{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliaghababaee/SLO_Asieh/blob/main/merged_model_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzlrpgcVBvZW",
        "outputId": "96555381-fa24-49cc-e6c3-12df4417cd6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/merged_data_final2.zip"
      ],
      "metadata": {
        "id": "yeJlZqnPE_1y",
        "outputId": "f833dce7-78eb-4be4-e1c1-87337ba0dca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/merged_data_final2.zip\n",
            " extracting: test_merged.pkl         \n",
            " extracting: test_merged_label.pkl   \n",
            " extracting: train_merged.pkl        \n",
            " extracting: train_merged_label.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/new_test_merged_data.zip"
      ],
      "metadata": {
        "id": "_qPNWUJyFGAm",
        "outputId": "ca567089-2f5c-473b-ab81-a01b31c0164e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/new_test_merged_data.zip\n",
            "replace test_merged.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: test_merged.pkl         \n",
            "replace test_merged_label.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: test_merged_label.pkl   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIwkl6vdMka-",
        "outputId": "59b945e2-9af2-4860-c3b8-af89963d6fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Slo_classification\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Slo_classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5KmBxL842CDf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2WqdgK3AfLh-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def Augmentation_oct (x_train, labels_train):\n",
        "\n",
        "    # augmentation\n",
        "    batch=np.zeros_like(x_train, dtype=np.float32)\n",
        "    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range= 5, # rotation\n",
        "        zoom_range= 0.2,\n",
        "        vertical_flip= True , # vertical fli\n",
        "        fill_mode='nearest',\n",
        "        data_format='channels_last',\n",
        "        #cval=0,\n",
        "          )\n",
        "\n",
        "\n",
        "    for i in range(len(x_train)):\n",
        "        x1=x_train[i,:,:,:].copy()\n",
        "        x1=x1.reshape((1, ) + x1.shape)\n",
        "        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n",
        "\n",
        "\n",
        "        batch[i,:,:,:] = x.next()\n",
        "        batch_label[i] = labels_train[i]\n",
        "\n",
        "    ###################################################################\n",
        "    # Final data\n",
        "    ###################################################################\n",
        "\n",
        "    x = np.concatenate([x_train,batch])\n",
        "\n",
        "    labels = np.concatenate([labels_train,batch_label])\n",
        "\n",
        "    ############################\n",
        "\n",
        "    ############################\n",
        "    return x, labels"
      ],
      "metadata": {
        "id": "2futtCo08HIC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aqhPh34AfcOe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def Augmentation_slo (x_train, labels_train):\n",
        "\n",
        "    # augmentation\n",
        "    batch=np.zeros_like(x_train, dtype=np.float32)\n",
        "    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range= 5, # rotation\n",
        "        width_shift_range= [-30, 30], # horizontal shift\n",
        "        height_shift_range= [-5, 5] , # vertical shift\n",
        "        zoom_range= 0.2,\n",
        "        vertical_flip= True , # vertical flip\n",
        "        brightness_range= [0.2, 1.5],\n",
        "          )\n",
        "\n",
        "    for i in range(len(x_train)):\n",
        "        x1=x_train[i,:,:,:].copy()\n",
        "        x1=x1.reshape((1, ) + x1.shape)\n",
        "        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n",
        "\n",
        "\n",
        "        batch[i,:,:,:] = x.next()\n",
        "        batch_label[i] = labels_train[i]\n",
        "\n",
        "    ###################################################################\n",
        "    # Final data\n",
        "    ###################################################################\n",
        "\n",
        "    x = np.concatenate([x_train,batch])\n",
        "\n",
        "    labels = np.concatenate([labels_train,batch_label])\n",
        "\n",
        "    ############################\n",
        "\n",
        "    ############################\n",
        "    return x, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PkgmjZZ8foyX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import sklearn\n",
        "\n",
        "# TP = confusion[1,1] # true positive\n",
        "# TN = confusion[0,0] # true negatives\n",
        "# FP = confusion[0,1] # false positives\n",
        "# FN = confusion[1,0] # false negatives\n",
        "\n",
        "def metrics_calculation(y_valid, y_pred, y_prob):\n",
        "\n",
        "    #####################################################\n",
        "    #Get the confusion matrix\n",
        "    #####################################################\n",
        "    ROC_AUC = roc_auc_score(y_valid, y_prob)\n",
        "    f1 = metrics.f1_score(y_valid, y_pred, average='weighted')\n",
        "    precision, recall, thresholds = precision_recall_curve(y_valid, y_prob)\n",
        "    P_R_AUC = auc(recall, precision)\n",
        "    cm = sklearn.metrics.confusion_matrix(y_valid, y_pred, normalize='pred')\n",
        "    #Now the normalize the diagonal entries\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    class_acc = cm.diagonal()\n",
        "\n",
        "    Specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "    Sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    Precision   = cm[1,1]/(cm[0,1]+cm[1,1])\n",
        "\n",
        "\n",
        "    return Specificity, Sensitivity, Precision, f1, ROC_AUC, P_R_AUC, class_acc, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GNzoww19fvXa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "def curve_ploting(ax, axx, mean_fpr, aucs, tprs, y_test, y_pred, classifier, kernel=[]):\n",
        "\n",
        "    ###################### Continuing Ploting ROC curve for each fold and the mean ############\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    ax.plot(\n",
        "        mean_fpr,\n",
        "        mean_tpr,\n",
        "        color=\"b\",\n",
        "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
        "        lw=2,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    ax.fill_between(\n",
        "        mean_fpr,\n",
        "        tprs_lower,\n",
        "        tprs_upper,\n",
        "        color=\"grey\",\n",
        "        alpha=0.2,\n",
        "        label=r\"$\\pm$ 1 std. dev.\",\n",
        "    )\n",
        "\n",
        "    ax.set(\n",
        "        xlim=[-0.05, 1.05],\n",
        "        ylim=[-0.05, 1.05],\n",
        "    )\n",
        "\n",
        "    if kernel:\n",
        "        ax.set_title(f\"ROC Curve of {classifier} classifier ({kernel} kernel) \")\n",
        "    else:\n",
        "        ax.set_title(f\"ROC Curve of {classifier} classifier\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "\n",
        "    ###################### Continuing Ploting P_R_curve for each fold and the mean ############\n",
        "    ###\n",
        "\n",
        "    no_skill = len(np.array(y_test)[np.array(y_test)==1]) / len(np.array(y_test))\n",
        "\n",
        "    axx.plot([0, 1], [no_skill, no_skill], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "    axx.plot(\n",
        "        recall,\n",
        "        precision,\n",
        "        color=\"b\",\n",
        "        label=r\"Mean P_R curve (AUC =  %0.2f)\" % (auc(recall, precision)),\n",
        "        lw=2,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "\n",
        "    # axis labels\n",
        "    axx.set_xlabel('Recall')\n",
        "    axx.set_ylabel('Precision')\n",
        "    # show the legend\n",
        "    axx.legend(loc=\"lower left\")\n",
        "    if kernel:\n",
        "        axx.set_title(f'Precision-Recall Curve of {classifier} classifier ({kernel} kernel)')\n",
        "    else:\n",
        "        axx.set_title(f'Precision-Recall Curve of {classifier} classifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bb-zc6m7f2fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def fold_curves(ax, axx, y_valid, fold_number, mean_fpr, pred_proba, tprs=[], aucs=[]):\n",
        "    ############ ROC Curve\n",
        "    lr_fpr, lr_tpr, _ = roc_curve(y_valid, pred_proba)\n",
        "    roc_auc = roc_auc_score(y_valid, pred_proba)\n",
        "    ax.plot(lr_fpr, lr_tpr, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, roc_auc))\n",
        "    # axis labels\n",
        "    ax.set_xlabel('False Positive Rate (Positive label: 1.0)')\n",
        "    ax.set_ylabel('True Positive Rate (Positive label: 1.0)')\n",
        "\n",
        "    interp_tpr = np.interp(mean_fpr, lr_fpr, lr_tpr)\n",
        "    interp_tpr[0] = 0.0\n",
        "    tprs.append(interp_tpr)\n",
        "    aucs.append(roc_auc)\n",
        "\n",
        "\n",
        "    ############ P_R Curve\n",
        "    precision, recall, _ = precision_recall_curve(y_valid, pred_proba)\n",
        "    # plot the model precision-recall curve\n",
        "    axx.plot(recall, precision, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, auc(recall, precision)))\n",
        "\n",
        "    return tprs, aucs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### SLO model\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "slo_model =  tf.keras.applications.resnet.ResNet101(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(128,128,3),\n",
        "    )\n",
        "\n",
        "for layer in slo_model.layers:\n",
        "    layer._name = 'SLO_' + layer.name\n",
        "\n",
        "new_model = Model(inputs=slo_model.input, outputs=slo_model.output)\n",
        "\n",
        "new_model.save('slo_model_resnet101.h5')"
      ],
      "metadata": {
        "id": "Utb-JBWKBQ-s",
        "outputId": "29081128-2aec-4586-f858-f2fdab28741a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171446536/171446536 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_img_oct"
      ],
      "metadata": {
        "id": "BOmfvuSuXPaH",
        "outputId": "34eec759-ecaf-4c58-ef8b-6f17ca9976a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_img_oct' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-53f956e1c6d0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_img_oct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_img_oct' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merged CNN model for SLO and OCT images\n",
        "\n",
        "# Create two CNN models with the same fully connected layers\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "def merged_model(input_img_slo ,input_img_oct):\n",
        "\n",
        "    ### SLO model\n",
        "    slo_model = load_model('slo_model_resnet101.h5')\n",
        "\n",
        "    for layer in slo_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "    #OCT model\n",
        "\n",
        "    oct_model =  tf.keras.applications.resnet.ResNet101(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_img_oct,\n",
        "        )\n",
        "\n",
        "\n",
        "    oct_model.get_layer(index = 0)._name = 'OCT'\n",
        "\n",
        "    for layer in oct_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "    inputs_slo = tf.keras.layers.Input(input_img_slo)\n",
        "    slo_output = tf.keras.layers.Flatten()(slo_model(inputs_slo))\n",
        "\n",
        "\n",
        "    inputs_oct = tf.keras.layers.Input(input_img_oct)\n",
        "    oct_output = tf.keras.layers.Flatten()(oct_model(inputs_oct))\n",
        "\n",
        "\n",
        "    model = tf.keras.layers.Concatenate(axis=-1)([slo_output, oct_output])\n",
        "\n",
        "\n",
        "    model = tf.keras.layers.Dropout(0.5)(model)\n",
        "\n",
        "    model = tf.keras.layers.Dense(617, activation='relu')(model)\n",
        "\n",
        "    model = tf.keras.layers.Dropout(0.4)(model)\n",
        "\n",
        "    model = tf.keras.layers.Dense(38, activation='relu')(model)\n",
        "\n",
        "    model = tf.keras.layers.Dropout(0.5)(model)\n",
        "\n",
        "\n",
        "    #model = tf.keras.layers.Dense(96, activation='relu')(model)\n",
        "\n",
        "    #model = tf.keras.layers.Dropout(0.5)(model)\n",
        "\n",
        "\n",
        "    #model = tf.keras.layers.Dense(3732, activation='relu')(model)\n",
        "\n",
        "    #model = tf.keras.layers.Dropout(0.2)(model)\n",
        "\n",
        "\n",
        "    #model = tf.keras.layers.Dense(196, activation='relu')(model)\n",
        "\n",
        "    #model = tf.keras.layers.Dropout(0.7)(model)\n",
        "\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, 'sigmoid')(model)\n",
        "\n",
        "    model_merged = tf.keras.Model([inputs_slo, inputs_oct] , outputs)\n",
        "\n",
        "    print(model_merged.summary())\n",
        "\n",
        "    return model_merged\n"
      ],
      "metadata": {
        "id": "SMeiv784pNnu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "d8cj2xfPfhyn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def preparing(x, y):\n",
        "\n",
        "    data_slo  = []\n",
        "    data_oct  = []\n",
        "    label     = []\n",
        "    for i in x:\n",
        "      for j in range(len(x[i])):\n",
        "          data_slo.append(np.array(x[i][j][0])/255)\n",
        "          data_oct.append(np.array(x[i][j][1])*255)\n",
        "          label.append(y[i])\n",
        "    data_slo = np.reshape(data_slo, np.shape(data_slo))\n",
        "    data_oct = np.reshape(data_oct, np.shape(data_oct))\n",
        "    return data_slo, data_oct, np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58dYkyaFgBM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a6165b-837e-4490-ac96-a2e69ff3cd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------          \n",
            " \t\t\t 1th fold \n",
            "---------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_50 (InputLayer)       [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_51 (InputLayer)       [(None, 60, 256, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 4, 4, 2048)           4265817   ['input_50[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " resnet101 (Functional)      (None, 2, 8, 2048)           4265817   ['input_51[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " flatten_31 (Flatten)        (None, 32768)                0         ['model[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_32 (Flatten)        (None, 32768)                0         ['resnet101[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 65536)                0         ['flatten_31[0][0]',          \n",
            " e)                                                                  'flatten_32[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_45 (Dropout)        (None, 65536)                0         ['concatenate_15[0][0]']      \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 617)                  4043632   ['dropout_45[0][0]']          \n",
            "                                                          9                                       \n",
            "                                                                                                  \n",
            " dropout_46 (Dropout)        (None, 617)                  0         ['dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 38)                   23484     ['dropout_46[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_47 (Dropout)        (None, 38)                   0         ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 1)                    39        ['dropout_47[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125776204 (479.80 MB)\n",
            "Trainable params: 40459852 (154.34 MB)\n",
            "Non-trainable params: 85316352 (325.46 MB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_50 (InputLayer)       [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_51 (InputLayer)       [(None, 60, 256, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 4, 4, 2048)           4265817   ['input_50[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " resnet101 (Functional)      (None, 2, 8, 2048)           4265817   ['input_51[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " flatten_31 (Flatten)        (None, 32768)                0         ['model[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_32 (Flatten)        (None, 32768)                0         ['resnet101[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 65536)                0         ['flatten_31[0][0]',          \n",
            " e)                                                                  'flatten_32[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_45 (Dropout)        (None, 65536)                0         ['concatenate_15[0][0]']      \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 617)                  4043632   ['dropout_45[0][0]']          \n",
            "                                                          9                                       \n",
            "                                                                                                  \n",
            " dropout_46 (Dropout)        (None, 617)                  0         ['dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 38)                   23484     ['dropout_46[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_47 (Dropout)        (None, 38)                   0         ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 1)                    39        ['dropout_47[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125776204 (479.80 MB)\n",
            "Trainable params: 40459852 (154.34 MB)\n",
            "Non-trainable params: 85316352 (325.46 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "21/22 [===========================>..] - ETA: 0s - loss: 0.8991 - accuracy: 0.6250 - auc: 0.6691\n",
            "Epoch 1: val_loss improved from inf to 0.41424, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 25s 581ms/step - loss: 0.8953 - accuracy: 0.6272 - auc: 0.6709 - val_loss: 0.4142 - val_accuracy: 0.8837 - val_auc: 0.9087 - lr: 5.2335e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8373 - auc: 0.9165\n",
            "Epoch 2: val_loss improved from 0.41424 to 0.34126, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 10s 464ms/step - loss: 0.3849 - accuracy: 0.8373 - auc: 0.9165 - val_loss: 0.3413 - val_accuracy: 0.8837 - val_auc: 0.8957 - lr: 5.2335e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.8817 - auc: 0.9460\n",
            "Epoch 3: val_loss improved from 0.34126 to 0.27750, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 6s 273ms/step - loss: 0.3013 - accuracy: 0.8817 - auc: 0.9460 - val_loss: 0.2775 - val_accuracy: 0.8837 - val_auc: 0.9348 - lr: 5.2335e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.9231 - auc: 0.9779\n",
            "Epoch 4: val_loss improved from 0.27750 to 0.21981, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 436ms/step - loss: 0.1895 - accuracy: 0.9231 - auc: 0.9779 - val_loss: 0.2198 - val_accuracy: 0.8837 - val_auc: 0.9609 - lr: 5.2335e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9172 - auc: 0.9740\n",
            "Epoch 5: val_loss improved from 0.21981 to 0.19600, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 5s 252ms/step - loss: 0.2016 - accuracy: 0.9172 - auc: 0.9740 - val_loss: 0.1960 - val_accuracy: 0.9302 - val_auc: 0.9609 - lr: 5.2335e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9467 - auc: 0.9877\n",
            "Epoch 6: val_loss improved from 0.19600 to 0.12111, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 437ms/step - loss: 0.1375 - accuracy: 0.9467 - auc: 0.9877 - val_loss: 0.1211 - val_accuracy: 0.9302 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9556 - auc: 0.9921\n",
            "Epoch 7: val_loss improved from 0.12111 to 0.09533, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 6s 277ms/step - loss: 0.1121 - accuracy: 0.9556 - auc: 0.9921 - val_loss: 0.0953 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9615 - auc: 0.9922\n",
            "Epoch 8: val_loss did not improve from 0.09533\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.1064 - accuracy: 0.9615 - auc: 0.9922 - val_loss: 0.1400 - val_accuracy: 0.9070 - val_auc: 0.9826 - lr: 5.2335e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9615 - auc: 0.9949\n",
            "Epoch 9: val_loss improved from 0.09533 to 0.09151, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 8s 398ms/step - loss: 0.0939 - accuracy: 0.9615 - auc: 0.9949 - val_loss: 0.0915 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.9734 - auc: 0.9927\n",
            "Epoch 10: val_loss improved from 0.09151 to 0.08204, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 8s 358ms/step - loss: 0.0842 - accuracy: 0.9734 - auc: 0.9927 - val_loss: 0.0820 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9763 - auc: 0.9982\n",
            "Epoch 11: val_loss did not improve from 0.08204\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0594 - accuracy: 0.9763 - auc: 0.9982 - val_loss: 0.1139 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9763 - auc: 0.9984\n",
            "Epoch 12: val_loss did not improve from 0.08204\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0586 - accuracy: 0.9763 - auc: 0.9984 - val_loss: 0.0919 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9793 - auc: 0.9986\n",
            "Epoch 13: val_loss improved from 0.08204 to 0.05729, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 429ms/step - loss: 0.0486 - accuracy: 0.9793 - auc: 0.9986 - val_loss: 0.0573 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.9882 - auc: 0.9994\n",
            "Epoch 14: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0372 - accuracy: 0.9882 - auc: 0.9994 - val_loss: 0.0692 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0802 - accuracy: 0.9734 - auc: 0.9946\n",
            "Epoch 15: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0802 - accuracy: 0.9734 - auc: 0.9946 - val_loss: 0.0869 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9941 - auc: 0.9995\n",
            "Epoch 16: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 114ms/step - loss: 0.0297 - accuracy: 0.9941 - auc: 0.9995 - val_loss: 0.1066 - val_accuracy: 0.9535 - val_auc: 0.9913 - lr: 5.2335e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9763 - auc: 0.9992\n",
            "Epoch 17: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.0413 - accuracy: 0.9763 - auc: 0.9992 - val_loss: 0.1188 - val_accuracy: 0.9535 - val_auc: 0.9913 - lr: 5.2335e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9882 - auc: 0.9996\n",
            "Epoch 18: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0309 - accuracy: 0.9882 - auc: 0.9996 - val_loss: 0.1523 - val_accuracy: 0.9535 - val_auc: 0.9913 - lr: 5.2335e-05\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9822 - auc: 0.9975\n",
            "Epoch 19: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0597 - accuracy: 0.9822 - auc: 0.9975 - val_loss: 0.0841 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9941 - auc: 0.9999\n",
            "Epoch 20: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0241 - accuracy: 0.9941 - auc: 0.9999 - val_loss: 0.1010 - val_accuracy: 0.9535 - val_auc: 0.9989 - lr: 5.2335e-05\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9852 - auc: 0.9961\n",
            "Epoch 21: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0504 - accuracy: 0.9852 - auc: 0.9961 - val_loss: 0.0672 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9852 - auc: 0.9995\n",
            "Epoch 22: val_loss did not improve from 0.05729\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0343 - accuracy: 0.9852 - auc: 0.9995 - val_loss: 0.0823 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9911 - auc: 0.9998\n",
            "Epoch 23: val_loss improved from 0.05729 to 0.03196, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 407ms/step - loss: 0.0273 - accuracy: 0.9911 - auc: 0.9998 - val_loss: 0.0320 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 24: val_loss improved from 0.03196 to 0.03060, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 424ms/step - loss: 0.0125 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0306 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9911 - auc: 0.9996\n",
            "Epoch 25: val_loss did not improve from 0.03060\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0290 - accuracy: 0.9911 - auc: 0.9996 - val_loss: 0.0493 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9882 - auc: 0.9997\n",
            "Epoch 26: val_loss improved from 0.03060 to 0.02271, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 8s 382ms/step - loss: 0.0267 - accuracy: 0.9882 - auc: 0.9997 - val_loss: 0.0227 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.02271\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 28/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9852 - auc: 0.9996\n",
            "Epoch 28: val_loss did not improve from 0.02271\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.0247 - accuracy: 0.9852 - auc: 0.9996 - val_loss: 0.0328 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 29/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9911 - auc: 0.9998\n",
            "Epoch 29: val_loss improved from 0.02271 to 0.01652, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 409ms/step - loss: 0.0213 - accuracy: 0.9911 - auc: 0.9998 - val_loss: 0.0165 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 30/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9941 - auc: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0118 - accuracy: 0.9941 - auc: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 31/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 31: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0089 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 32/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 32: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0048 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 33/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 33: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0125 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 34/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 34: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0107 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 35/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 35: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0043 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 36/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9970 - auc: 0.9999\n",
            "Epoch 36: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0140 - accuracy: 0.9970 - auc: 0.9999 - val_loss: 0.0510 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 37/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 37: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0073 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 38/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9941 - auc: 0.9999\n",
            "Epoch 38: val_loss did not improve from 0.01652\n",
            "22/22 [==============================] - 3s 118ms/step - loss: 0.0128 - accuracy: 0.9941 - auc: 0.9999 - val_loss: 0.0369 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 39/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 39: val_loss improved from 0.01652 to 0.01587, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 405ms/step - loss: 0.0079 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0159 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 40/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 40: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 41/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 41: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0106 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 42/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 42: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 3s 117ms/step - loss: 0.0040 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9535 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 43/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9941 - auc: 0.9998\n",
            "Epoch 43: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0164 - accuracy: 0.9941 - auc: 0.9998 - val_loss: 0.0285 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 44/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 44: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 45/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9911 - auc: 0.9999\n",
            "Epoch 45: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.0107 - accuracy: 0.9911 - auc: 0.9999 - val_loss: 0.0192 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 46/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 46: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0230 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 47/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 47: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 48/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 48: val_loss did not improve from 0.01587\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0041 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 49/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 49: val_loss improved from 0.01587 to 0.01490, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 9s 408ms/step - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 50/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 50: val_loss improved from 0.01490 to 0.00866, saving model to slo_oct1.h5\n",
            "22/22 [==============================] - 6s 301ms/step - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 51/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 51: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 52/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 52: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0055 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 53/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9941 - auc: 1.0000\n",
            "Epoch 53: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 109ms/step - loss: 0.0093 - accuracy: 0.9941 - auc: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 54/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9970 - auc: 0.9999\n",
            "Epoch 54: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0115 - accuracy: 0.9970 - auc: 0.9999 - val_loss: 0.0181 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 55/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 55: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 56/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 56: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0060 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 57/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 57: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0057 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9302 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 58/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9911 - auc: 1.0000\n",
            "Epoch 58: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 3s 119ms/step - loss: 0.0132 - accuracy: 0.9911 - auc: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 59/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 59: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0080 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 60/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 60: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 61/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 61: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.0055 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9767 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 62/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 62: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0079 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 63/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 63: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 3s 120ms/step - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 64/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 64: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0069 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 65/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 65: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 66/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 66: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 67/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9970 - auc: 1.0000\n",
            "Epoch 67: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0080 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.0231 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 68/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9970 - auc: 0.9999\n",
            "Epoch 68: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.0101 - accuracy: 0.9970 - auc: 0.9999 - val_loss: 0.0208 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 69/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 69: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 70/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 70: val_loss did not improve from 0.00866\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0061 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000 - val_auc: 1.0000 - lr: 5.2335e-06\n",
            "Epoch 70: early stopping\n",
            "2/2 [==============================] - 4s 151ms/step\n",
            "accuracy of 1th fold : 1.0\n",
            "2/2 [==============================] - 0s 107ms/step\n",
            "test accuracy of 1th fold : 0.9464285714285714\n",
            "---------------------------------------------------------------------          \n",
            " \t\t\t 2th fold \n",
            "---------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_53 (InputLayer)       [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_54 (InputLayer)       [(None, 60, 256, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 4, 4, 2048)           4265817   ['input_53[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " resnet101 (Functional)      (None, 2, 8, 2048)           4265817   ['input_54[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " flatten_33 (Flatten)        (None, 32768)                0         ['model[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_34 (Flatten)        (None, 32768)                0         ['resnet101[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 65536)                0         ['flatten_33[0][0]',          \n",
            " e)                                                                  'flatten_34[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 65536)                0         ['concatenate_16[0][0]']      \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 617)                  4043632   ['dropout_48[0][0]']          \n",
            "                                                          9                                       \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 617)                  0         ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 38)                   23484     ['dropout_49[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 38)                   0         ['dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1)                    39        ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125776204 (479.80 MB)\n",
            "Trainable params: 40459852 (154.34 MB)\n",
            "Non-trainable params: 85316352 (325.46 MB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_53 (InputLayer)       [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " input_54 (InputLayer)       [(None, 60, 256, 3)]         0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 4, 4, 2048)           4265817   ['input_53[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " resnet101 (Functional)      (None, 2, 8, 2048)           4265817   ['input_54[0][0]']            \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " flatten_33 (Flatten)        (None, 32768)                0         ['model[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_34 (Flatten)        (None, 32768)                0         ['resnet101[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 65536)                0         ['flatten_33[0][0]',          \n",
            " e)                                                                  'flatten_34[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 65536)                0         ['concatenate_16[0][0]']      \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 617)                  4043632   ['dropout_48[0][0]']          \n",
            "                                                          9                                       \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 617)                  0         ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 38)                   23484     ['dropout_49[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 38)                   0         ['dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1)                    39        ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125776204 (479.80 MB)\n",
            "Trainable params: 40459852 (154.34 MB)\n",
            "Non-trainable params: 85316352 (325.46 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.7812 - accuracy: 0.7193 - auc: 0.7740\n",
            "Epoch 1: val_loss improved from inf to 0.33439, saving model to slo_oct2.h5\n",
            "22/22 [==============================] - 29s 596ms/step - loss: 0.7812 - accuracy: 0.7193 - auc: 0.7740 - val_loss: 0.3344 - val_accuracy: 0.8293 - val_auc: 0.9190 - lr: 5.2335e-05\n",
            "Epoch 2/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.3088 - accuracy: 0.8626 - auc: 0.9421\n",
            "Epoch 2: val_loss improved from 0.33439 to 0.29666, saving model to slo_oct2.h5\n",
            "22/22 [==============================] - 10s 457ms/step - loss: 0.3088 - accuracy: 0.8626 - auc: 0.9421 - val_loss: 0.2967 - val_accuracy: 0.9024 - val_auc: 0.9250 - lr: 5.2335e-05\n",
            "Epoch 3/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9181 - auc: 0.9715\n",
            "Epoch 3: val_loss did not improve from 0.29666\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.2240 - accuracy: 0.9181 - auc: 0.9715 - val_loss: 0.3077 - val_accuracy: 0.8780 - val_auc: 0.9190 - lr: 5.2335e-05\n",
            "Epoch 4/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9503 - auc: 0.9879\n",
            "Epoch 4: val_loss did not improve from 0.29666\n",
            "22/22 [==============================] - 2s 113ms/step - loss: 0.1396 - accuracy: 0.9503 - auc: 0.9879 - val_loss: 0.3901 - val_accuracy: 0.8780 - val_auc: 0.9452 - lr: 5.2335e-05\n",
            "Epoch 5/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9474 - auc: 0.9911\n",
            "Epoch 5: val_loss did not improve from 0.29666\n",
            "22/22 [==============================] - 3s 117ms/step - loss: 0.1214 - accuracy: 0.9474 - auc: 0.9911 - val_loss: 0.4214 - val_accuracy: 0.8780 - val_auc: 0.9429 - lr: 5.2335e-05\n",
            "Epoch 6/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9561 - auc: 0.9901\n",
            "Epoch 6: val_loss did not improve from 0.29666\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.1290 - accuracy: 0.9561 - auc: 0.9901 - val_loss: 0.6107 - val_accuracy: 0.8780 - val_auc: 0.9286 - lr: 5.2335e-05\n",
            "Epoch 7/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9327 - auc: 0.9851\n",
            "Epoch 7: val_loss improved from 0.29666 to 0.23248, saving model to slo_oct2.h5\n",
            "22/22 [==============================] - 6s 299ms/step - loss: 0.1634 - accuracy: 0.9327 - auc: 0.9851 - val_loss: 0.2325 - val_accuracy: 0.8780 - val_auc: 0.9762 - lr: 5.2335e-05\n",
            "Epoch 8/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9591 - auc: 0.9958\n",
            "Epoch 8: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 3s 118ms/step - loss: 0.0889 - accuracy: 0.9591 - auc: 0.9958 - val_loss: 0.2432 - val_accuracy: 0.8780 - val_auc: 0.9738 - lr: 5.2335e-05\n",
            "Epoch 9/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9854 - auc: 0.9977\n",
            "Epoch 9: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 110ms/step - loss: 0.0675 - accuracy: 0.9854 - auc: 0.9977 - val_loss: 0.4794 - val_accuracy: 0.8780 - val_auc: 0.9667 - lr: 5.2335e-05\n",
            "Epoch 10/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9795 - auc: 0.9981\n",
            "Epoch 10: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0614 - accuracy: 0.9795 - auc: 0.9981 - val_loss: 0.4395 - val_accuracy: 0.8780 - val_auc: 0.9690 - lr: 5.2335e-05\n",
            "Epoch 11/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9795 - auc: 0.9981\n",
            "Epoch 11: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0551 - accuracy: 0.9795 - auc: 0.9981 - val_loss: 0.4990 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-05\n",
            "Epoch 12/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9825 - auc: 0.9991\n",
            "Epoch 12: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0398 - accuracy: 0.9825 - auc: 0.9991 - val_loss: 0.7033 - val_accuracy: 0.8780 - val_auc: 0.9048 - lr: 5.2335e-05\n",
            "Epoch 13/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9825 - auc: 0.9957\n",
            "Epoch 13: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 114ms/step - loss: 0.0594 - accuracy: 0.9825 - auc: 0.9957 - val_loss: 0.4478 - val_accuracy: 0.8780 - val_auc: 0.9714 - lr: 5.2335e-05\n",
            "Epoch 14/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9854 - auc: 0.9995\n",
            "Epoch 14: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 3s 114ms/step - loss: 0.0337 - accuracy: 0.9854 - auc: 0.9995 - val_loss: 0.4054 - val_accuracy: 0.8780 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 15/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9854 - auc: 0.9990\n",
            "Epoch 15: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.0370 - accuracy: 0.9854 - auc: 0.9990 - val_loss: 0.4123 - val_accuracy: 0.8780 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 16/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9912 - auc: 0.9997\n",
            "Epoch 16: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0258 - accuracy: 0.9912 - auc: 0.9997 - val_loss: 0.4725 - val_accuracy: 0.8780 - val_auc: 1.0000 - lr: 5.2335e-05\n",
            "Epoch 17/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9825 - auc: 0.9993\n",
            "Epoch 17: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 108ms/step - loss: 0.0422 - accuracy: 0.9825 - auc: 0.9993 - val_loss: 0.3519 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-05\n",
            "Epoch 18/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9883 - auc: 0.9996\n",
            "Epoch 18: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0230 - accuracy: 0.9883 - auc: 0.9996 - val_loss: 0.3638 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-06\n",
            "Epoch 19/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9942 - auc: 0.9999\n",
            "Epoch 19: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 3s 119ms/step - loss: 0.0165 - accuracy: 0.9942 - auc: 0.9999 - val_loss: 0.3997 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-06\n",
            "Epoch 20/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9912 - auc: 0.9998\n",
            "Epoch 20: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 112ms/step - loss: 0.0217 - accuracy: 0.9912 - auc: 0.9998 - val_loss: 0.4273 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-06\n",
            "Epoch 21/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0139 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.8780 - val_auc: 0.9905 - lr: 5.2335e-06\n",
            "Epoch 22/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 22: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 111ms/step - loss: 0.0108 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.8780 - val_auc: 0.9929 - lr: 5.2335e-06\n",
            "Epoch 23/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9971 - auc: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 107ms/step - loss: 0.0147 - accuracy: 0.9971 - auc: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.8780 - val_auc: 0.9952 - lr: 5.2335e-06\n",
            "Epoch 24/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9942 - auc: 0.9998\n",
            "Epoch 24: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 3s 115ms/step - loss: 0.0175 - accuracy: 0.9942 - auc: 0.9998 - val_loss: 0.4840 - val_accuracy: 0.8780 - val_auc: 0.9952 - lr: 5.2335e-06\n",
            "Epoch 25/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9971 - auc: 0.9996\n",
            "Epoch 25: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 3s 114ms/step - loss: 0.0219 - accuracy: 0.9971 - auc: 0.9996 - val_loss: 0.4489 - val_accuracy: 0.8780 - val_auc: 0.9929 - lr: 5.2335e-06\n",
            "Epoch 26/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9942 - auc: 0.9998\n",
            "Epoch 26: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 106ms/step - loss: 0.0163 - accuracy: 0.9942 - auc: 0.9998 - val_loss: 0.4567 - val_accuracy: 0.8780 - val_auc: 0.9952 - lr: 5.2335e-06\n",
            "Epoch 27/100\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000 - auc: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.23248\n",
            "22/22 [==============================] - 2s 105ms/step - loss: 0.0083 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8780 - val_auc: 0.9952 - lr: 5.2335e-06\n",
            "Epoch 27: early stopping\n"
          ]
        }
      ],
      "source": [
        "#from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "images_train = pickle.load(open(\"train_merged.pkl\", 'rb'))\n",
        "labels_train = pickle.load(open(\"train_merged_label.pkl\", 'rb'))\n",
        "\n",
        "images_test = pickle.load(open(\"test_merged.pkl\", 'rb'))\n",
        "labels_test = pickle.load(open(\"test_merged_label.pkl\", 'rb'))\n",
        "\n",
        "images_test_slo, images_test_oct, labels_test_slo = preparing(images_test,labels_test)\n",
        "\n",
        "images_test_slo = np.repeat (images_test_slo, repeats = 3, axis = 3)\n",
        "images_test_oct = np.repeat (images_test_oct, repeats = 3, axis = 3)\n",
        "#####################################################################\n",
        "## Parameters\n",
        "#####################################################################\n",
        "channel = 3\n",
        "number_class = 2\n",
        "\n",
        "cnn_acc    = []\n",
        "cnn_se     = []\n",
        "cnn_sp     = []\n",
        "cnn_pr     = []\n",
        "cnn_f1     = []\n",
        "cnn_auc    = []\n",
        "cnn_pr_auc = []\n",
        "\n",
        "test_acc    = []\n",
        "test_se     = []\n",
        "test_sp     = []\n",
        "test_pr     = []\n",
        "test_f1     = []\n",
        "test_auc    = []\n",
        "test_pr_auc = []\n",
        "\n",
        "\n",
        "class_acc = np.zeros((number_class))\n",
        "class_acc_test = np.zeros((number_class))\n",
        "\n",
        "target_names = ['Normal' , 'MS']\n",
        "confusion_matrix = np.zeros((number_class, number_class))\n",
        "confusion_matrix_test = np.zeros((number_class, number_class))\n",
        "\n",
        "y_test = []\n",
        "tprs   = []\n",
        "aucs   = []\n",
        "y_pred = []\n",
        "x_test = {}\n",
        "\n",
        "mean_fpr  = np.linspace(0, 1, 100)\n",
        "fig, ax   = plt.subplots(figsize=(5, 5))\n",
        "fig1, ax1 = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "\n",
        "#### model parameters\n",
        "batch_size        = 16\n",
        "epoch             = 100\n",
        "learning_rate     =  5.2334776882413236e-05\n",
        "#####################################################################\n",
        "## Applying kfold\n",
        "#####################################################################\n",
        "\n",
        "nfold = 5  #please enter number of folds\n",
        "\n",
        "kf_nfold = StratifiedKFold(n_splits=nfold, random_state=42, shuffle=True)\n",
        "\n",
        "n = 0\n",
        "for train_index, val_index in kf_nfold.split(images_train,list(labels_train.values())):\n",
        "    n = n+1\n",
        "    # print(train_index, val_index)  # you can watch train and validation index using this comment\n",
        "    print(f'---------------------------------------------------------------------\\\n",
        "          \\n \\t\\t\\t {n}th fold \\n---------------------------------------------------------------------'\\\n",
        "          ,end = '\\n\\n\\n' )\n",
        "    x_train = {i: images_train[list(images_train.keys())[i]] for i in train_index}\n",
        "    x_valid = {i: images_train[list(images_train.keys())[i]] for i in val_index}\n",
        "\n",
        "    y_trainn = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "    y_validd = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "\n",
        "    ################## preparing\n",
        "\n",
        "    x_train_slo, x_train_oct, y_train = preparing(x_train,y_trainn)\n",
        "    x_valid_slo, x_valid_oct, y_valid = preparing(x_valid,y_validd)\n",
        "\n",
        "    x_test[n] = x_valid_slo\n",
        "    ################# Augmentation\n",
        "    x_train_slo, y_train_slo = Augmentation_slo(x_train_slo,y_train)\n",
        "\n",
        "    x_train_oct, y_train_oct = Augmentation_oct(x_train_oct,y_train)\n",
        "\n",
        "\n",
        "    indices = np.random.permutation (len (x_train_slo))\n",
        "    x_train_slo = x_train_slo [indices]\n",
        "    y_train_slo = y_train_slo [indices]\n",
        "\n",
        "    x_train_oct = x_train_oct [indices]\n",
        "    y_train_oct = y_train_oct [indices]\n",
        "\n",
        "\n",
        "    x_train_slo = np.repeat (x_train_slo, repeats = 3, axis = 3)\n",
        "\n",
        "    x_train_oct = np.repeat (x_train_oct, repeats = 3, axis = 3)\n",
        "\n",
        "    x_valid_slo = np.repeat (x_valid_slo, repeats = 3, axis = 3)\n",
        "\n",
        "    x_valid_oct = np.repeat (x_valid_oct, repeats = 3, axis = 3)\n",
        "\n",
        "    ####################################################################\n",
        "    # classification\n",
        "    ####################################################################\n",
        "\n",
        "    input_img_slo = (np.shape(x_train_slo)[1], np.shape(x_train_slo)[2], 3)\n",
        "    input_img_oct = (np.shape(x_train_oct)[1], np.shape(x_train_oct)[2], 3)\n",
        "\n",
        "    model = merged_model(input_img_slo=input_img_slo, input_img_oct=input_img_oct)\n",
        "\n",
        "    METRICS = [\n",
        "#      keras.metrics.TruePositives(name='tp'),\n",
        "#      keras.metrics.FalsePositives(name='fp'),\n",
        "#      keras.metrics.TrueNegatives(name='tn'),\n",
        "#      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "#      keras.metrics.Precision(name='precision'),\n",
        "#      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "#      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "      ]\n",
        "\n",
        "\n",
        "    my_optimizer =  tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=my_optimizer, loss=\"binary_crossentropy\", metrics=METRICS)\n",
        "    callbacks = [EarlyStopping(patience=20, verbose=1),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "        ModelCheckpoint(f'slo_oct{n}.h5', verbose=1, save_best_only=True, save_weights_only=True)]\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    #################################\n",
        "    ###### Applying model  ###########\n",
        "    #################################\n",
        "\n",
        "\n",
        "    results = model.fit([x_train_slo, x_train_oct], y_train_slo, batch_size=batch_size, epochs=epoch, callbacks=callbacks,\\\n",
        "                    validation_data=([x_valid_slo, x_valid_oct], np.asarray(y_valid, dtype=np.float64)))\n",
        "\n",
        "    #pruning_params = {\n",
        "        #'pruning_schedule': sparsity.PolynomialDecay (initial_sparsity = 0.5, final_sparsity = 0.9, begin_step = 0, end_step = 1000)\n",
        "    #}\n",
        "\n",
        "    #pruned_model = sparsity.prune_low_magnitude (model, **pruning_params)\n",
        "\n",
        "    #pruned_model.compile (optimizer = my_optimizer, loss = 'binary_crossentropy', metrics = METRICS)\n",
        "    #pruned_model.fit (x_train, epochs)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f\"Learning curve {n}th fold\")\n",
        "    plt.plot(results.history[\"loss\"][:-7], label=\"loss\")\n",
        "    plt.plot(results.history[\"val_loss\"][:-7], label=\"val_loss\")\n",
        "    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"log_loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f\"Learning curve {n}th fold\")\n",
        "    plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.plot( np.argmax(results.history[\"val_accuracy\"]), np.max(results.history[\"val_accuracy\"]),\\\n",
        "             marker=\"x\", color=\"r\", label=\"best accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    # load the best model\n",
        "    model.load_weights(f'slo_oct{n}.h5')\n",
        "\n",
        "\n",
        "    pred_proba = model.predict([x_valid_slo, x_valid_oct]).ravel()\n",
        "    pred_class = (pred_proba > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "    ##### calculating metrics\n",
        "\n",
        "    cnn_acc.append(metrics.accuracy_score(y_valid, pred_class))\n",
        "    print(f'accuracy of {n}th fold : {metrics.accuracy_score(y_valid, pred_class)}')\n",
        "    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(y_valid, pred_class, pred_proba)\n",
        "\n",
        "    cnn_sp.append(SP)\n",
        "    cnn_se.append(SE)\n",
        "    cnn_pr.append(PR)\n",
        "    cnn_f1.append(f1)\n",
        "    cnn_auc.append(ROC_AUC)\n",
        "    cnn_pr_auc.append(P_R_AUC)\n",
        "\n",
        "    #################### acc for each class ##################\n",
        "    class_acc = np.add(class_acc,Class_acc)\n",
        "\n",
        "    ###################### Total confusion_matrix for poly kernel ############\n",
        "    confusion_matrix = np.add(confusion_matrix,cm)\n",
        "\n",
        "######################## internal test\n",
        "    pred_proba_test = model.predict([images_test_slo, images_test_oct]).ravel()\n",
        "    pred_class_test = (pred_proba_test > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "    ##### calculating metrics\n",
        "\n",
        "    print(f'test accuracy of {n}th fold : {metrics.accuracy_score(labels_test_slo, pred_class_test)}')\n",
        "    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(labels_test_slo, pred_class_test, pred_proba_test)\n",
        "    test_acc.append(metrics.accuracy_score(labels_test_slo, pred_class_test))\n",
        "    test_sp.append(SP)\n",
        "    test_se.append(SE)\n",
        "    test_pr.append(PR)\n",
        "    test_f1.append(f1)\n",
        "    test_auc.append(ROC_AUC)\n",
        "    test_pr_auc.append(P_R_AUC)\n",
        "\n",
        "    #################### acc for each class ##################\n",
        "    class_acc_test  = np.add(class_acc_test,Class_acc)\n",
        "\n",
        "    ###################### Total confusion_matrix for poly kernel ############\n",
        "    confusion_matrix_test = np.add(confusion_matrix_test,cm)\n",
        "\n",
        "    # ###################### Ploting ROC and PR curves for each fold ############\n",
        "    # y_test = np.append(y_test, y_valid, axis = 0)\n",
        "    # y_pred = np.append(y_pred, pred_proba, axis = 0)\n",
        "    # ###\n",
        "    # tprs, aucs = fold_curves(ax, ax1, y_valid, n, mean_fpr, pred_proba, tprs, aucs)\n",
        "\n",
        "# ######################  the mean Ploting ROC and PR curves ############\n",
        "# ###\n",
        "# curve_ploting(ax, ax1, mean_fpr, aucs, tprs, y_test, y_pred, 'CNN' )\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# #######################################\n",
        "#     # ploting confusion matrix\n",
        "# #######################################\n",
        "# disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix/nfold, display_labels=target_names)\n",
        "# disp.plot()\n",
        "\n",
        "\n",
        "########################################\n",
        "#     Metrics printing\n",
        "########################################\n",
        "cnn_accc     = np.mean(cnn_acc)\n",
        "cnn_spp      = np.mean(cnn_sp)\n",
        "cnn_see      = np.mean(cnn_se)\n",
        "cnn_prr      = np.mean(cnn_pr)\n",
        "cnn_f11      = np.mean(cnn_f1)\n",
        "cnn_aucc     = np.mean(cnn_auc)\n",
        "cnn_pr_aucc  = np.mean(cnn_pr_auc)\n",
        "\n",
        "###################### internal test\n",
        "test_accc     = np.mean(test_acc)\n",
        "test_spp      = np.mean(test_sp)\n",
        "test_see      = np.mean(test_se)\n",
        "test_prr      = np.mean(test_pr)\n",
        "test_f11      = np.mean(test_f1)\n",
        "test_aucc     = np.mean(test_auc)\n",
        "test_pr_aucc  = np.mean(test_pr_auc)\n",
        "\n",
        "#################### acc for each class ##################\n",
        "class_acc  = class_acc/nfold\n",
        "class_acc_test  = class_acc_test/nfold\n",
        "\n",
        "print('cnn_acc     = %f' % cnn_accc)\n",
        "print('cnn_sp      = %f' % cnn_spp)\n",
        "print('cnn_se      = %f' % cnn_see)\n",
        "print('cnn_pr      = %f' % cnn_prr)\n",
        "print('cnn_f1      = %f' % cnn_f11)\n",
        "print('cnn_auc     = %f' % cnn_aucc)\n",
        "print('cnn_pr_auc  = %f' % cnn_pr_aucc, end='\\n\\n')\n",
        "\n",
        "\n",
        "print('acc of class %s' % target_names[0], '= %f' % class_acc[0])\n",
        "print('acc of class %s' % target_names[1], '= %f' % class_acc[1], end='\\n\\n')\n",
        "\n",
        "print('test_acc     = %f' % test_accc)\n",
        "print('test_sp      = %f' % test_spp)\n",
        "print('test_se      = %f' % test_see)\n",
        "print('test_pr      = %f' % test_prr)\n",
        "print('test_f1      = %f' % test_f11)\n",
        "print('test_auc     = %f' % test_aucc)\n",
        "print('test_pr_auc  = %f' % test_pr_aucc, end='\\n\\n')\n",
        "\n",
        "\n",
        "print('test acc of class %s' % target_names[0], '= %f' % class_acc_test[0])\n",
        "print('test acc of class %s' % target_names[1], '= %f' % class_acc_test[1], end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBrLId0sE6Kb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}