{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliaghababaee/SLO_Asieh/blob/main/VGG_%2B_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBagzD7at0TS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZJ4AJnMNWpL",
        "outputId": "df7157cf-30f9-41c3-f1b6-4fe53479ee10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5KmBxL842CDf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2WqdgK3AfLh-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/train_thickness_retina_iran.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d79382-48eb-430e-ebfe-13e3f8deb985",
        "id": "EShLuXN8vGY9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/train_thickness_retina_iran.zip\n",
            " extracting: train_labels.pkl        \n",
            " extracting: train_thickness_retina.pkl  \n",
            " extracting: train_sp.pkl            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/test_thickness_retina_iran.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b68b4b-cfb9-49dd-fb4e-85cc63cda416",
        "id": "raLWKZg2vGY9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/test_thickness_retina_iran.zip\n",
            " extracting: test_labels.pkl         \n",
            " extracting: test_thickness_retina.pkl  \n",
            " extracting: test_sp.pkl             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/train_SLO_iran.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZD6wTi_GBoD",
        "outputId": "9c6ea05c-2897-478f-c515-d80a28dca98f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/train_SLO_iran.zip\n",
            " extracting: train_slo_iran.pkl      \n",
            " extracting: train_labels_Iran.pkl   \n",
            " extracting: train_sp_iran.pkl       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/test_SLO_iran.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m7cRiWbGBr2",
        "outputId": "385f1d4f-63d2-4b94-fc49-bf92d4f932f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/test_SLO_iran.zip\n",
            " extracting: test_slo_iran.pkl       \n",
            " extracting: test_labels_Iran.pkl    \n",
            " extracting: test_sp_iran.pkl        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "shEJuyQAwvel"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "L8o2VchRwven"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "import numpy as np\n",
        "import pickle\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6eT7xZu5SecF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def Augmentation_1 (x_train, labels_train):\n",
        "\n",
        "    # augmentation\n",
        "    batch=np.zeros_like(x_train, dtype=np.float32)\n",
        "    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n",
        "\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range= 5, # rotation\n",
        "    zoom_range = 0.1,\n",
        "    fill_mode='nearest',\n",
        "    data_format='channels_last',\n",
        "      )\n",
        "\n",
        "\n",
        "    for i in range(len(x_train)):\n",
        "        x1=x_train[i,:,:,:].copy()\n",
        "        x1=x1.reshape((1, ) + x1.shape)\n",
        "        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n",
        "\n",
        "\n",
        "        batch[i,:,:,:] = x.next()\n",
        "        batch_label[i] = labels_train[i]\n",
        "\n",
        "    return batch, batch_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "aqhPh34AfcOe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def Augmentation_2 (x_train, labels_train):\n",
        "\n",
        "    # augmentation\n",
        "    batch=np.zeros_like(x_train, dtype=np.float32)\n",
        "    batch_label=np.zeros_like(labels_train, dtype=np.float32)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range= 5, # rotation\n",
        "        width_shift_range= [-30, 30], # horizontal shift\n",
        "        #height_shift_range= [-5, 5] , # vertical shift\n",
        "        zoom_range= 0.2,\n",
        "        vertical_flip= True , # vertical flip\n",
        "        #brightness_range= [0.2, 1.5],\n",
        "          )\n",
        "\n",
        "    for i in range(len(x_train)):\n",
        "        x1=x_train[i,:,:,:].copy()\n",
        "        x1=x1.reshape((1, ) + x1.shape)\n",
        "        x = datagen.flow(x1, batch_size=1, seed=2020) # to make the result reproducible\n",
        "\n",
        "\n",
        "        batch[i,:,:,:] = x.next()\n",
        "        batch_label[i] = labels_train[i]\n",
        "\n",
        "    ###################################################################\n",
        "    # Final data\n",
        "    ###################################################################\n",
        "\n",
        "    x = np.concatenate([x_train,batch])\n",
        "\n",
        "    labels = np.concatenate([labels_train,batch_label])\n",
        "\n",
        "    ############################\n",
        "\n",
        "    ############################\n",
        "    return x, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "wHGAuOGlHAf0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "d8cj2xfPfhyn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def preparing(x, y):\n",
        "\n",
        "    data  = []\n",
        "    label = []\n",
        "    for i in x:\n",
        "        for j in range(len(x[i])):\n",
        "\n",
        "            #data.append(np.array(x[i][j]))\n",
        "            #label.append(y[i])\n",
        "\n",
        "            img = resize (x[i][j], (224, 224, 1), mode = 'constant', preserve_range= True)\n",
        "            data.append(img)\n",
        "            label.append(y[i])\n",
        "\n",
        "    data = np.reshape(data, np.shape(data))\n",
        "    return data, np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PkgmjZZ8foyX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import sklearn\n",
        "\n",
        "# TP = confusion[1,1] # true positive\n",
        "# TN = confusion[0,0] # true negatives\n",
        "# FP = confusion[0,1] # false positives\n",
        "# FN = confusion[1,0] # false negatives\n",
        "\n",
        "def metrics_calculation(y_valid, y_pred, y_prob):\n",
        "\n",
        "    #####################################################\n",
        "    #Get the confusion matrix\n",
        "    #####################################################\n",
        "    ROC_AUC = roc_auc_score(y_valid, y_prob)\n",
        "    f1 = metrics.f1_score(y_valid, y_pred, average='weighted')\n",
        "    precision, recall, thresholds = precision_recall_curve(y_valid, y_prob)\n",
        "    P_R_AUC = auc(recall, precision)\n",
        "    cm = sklearn.metrics.confusion_matrix(y_valid, y_pred, normalize='pred')\n",
        "    #Now the normalize the diagonal entries\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    class_acc = cm.diagonal()\n",
        "\n",
        "    Specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "    Sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "    Precision   = cm[1,1]/(cm[0,1]+cm[1,1])\n",
        "\n",
        "\n",
        "    return Specificity, Sensitivity, Precision, f1, ROC_AUC, P_R_AUC, class_acc, cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GNzoww19fvXa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "def curve_ploting(ax, axx, mean_fpr, aucs, tprs, y_test, y_pred, classifier, kernel=[]):\n",
        "\n",
        "    ###################### Continuing Ploting ROC curve for each fold and the mean ############\n",
        "\n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = auc(mean_fpr, mean_tpr)\n",
        "    std_auc = np.std(aucs)\n",
        "    ax.plot(\n",
        "        mean_fpr,\n",
        "        mean_tpr,\n",
        "        color=\"b\",\n",
        "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
        "        lw=2,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "    ax.fill_between(\n",
        "        mean_fpr,\n",
        "        tprs_lower,\n",
        "        tprs_upper,\n",
        "        color=\"grey\",\n",
        "        alpha=0.2,\n",
        "        label=r\"$\\pm$ 1 std. dev.\",\n",
        "    )\n",
        "\n",
        "    ax.set(\n",
        "        xlim=[-0.05, 1.05],\n",
        "        ylim=[-0.05, 1.05],\n",
        "    )\n",
        "\n",
        "    if kernel:\n",
        "        ax.set_title(f\"ROC Curve of {classifier} classifier ({kernel} kernel) \")\n",
        "    else:\n",
        "        ax.set_title(f\"ROC Curve of {classifier} classifier\")\n",
        "    ax.legend(loc=\"lower right\")\n",
        "\n",
        "    ###################### Continuing Ploting P_R_curve for each fold and the mean ############\n",
        "    ###\n",
        "\n",
        "    no_skill = len(np.array(y_test)[np.array(y_test)==1]) / len(np.array(y_test))\n",
        "\n",
        "    axx.plot([0, 1], [no_skill, no_skill], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "    axx.plot(\n",
        "        recall,\n",
        "        precision,\n",
        "        color=\"b\",\n",
        "        label=r\"Mean P_R curve (AUC =  %0.2f)\" % (auc(recall, precision)),\n",
        "        lw=2,\n",
        "        alpha=0.8,\n",
        "    )\n",
        "\n",
        "\n",
        "    # axis labels\n",
        "    axx.set_xlabel('Recall')\n",
        "    axx.set_ylabel('Precision')\n",
        "    # show the legend\n",
        "    axx.legend(loc=\"lower left\")\n",
        "    if kernel:\n",
        "        axx.set_title(f'Precision-Recall Curve of {classifier} classifier ({kernel} kernel)')\n",
        "    else:\n",
        "        axx.set_title(f'Precision-Recall Curve of {classifier} classifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bb-zc6m7f2fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc, roc_curve, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "def fold_curves(ax, axx, y_valid, fold_number, mean_fpr, pred_proba, tprs=[], aucs=[]):\n",
        "    ############ ROC Curve\n",
        "    lr_fpr, lr_tpr, _ = roc_curve(y_valid, pred_proba)\n",
        "    roc_auc = roc_auc_score(y_valid, pred_proba)\n",
        "    ax.plot(lr_fpr, lr_tpr, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, roc_auc))\n",
        "    # axis labels\n",
        "    ax.set_xlabel('False Positive Rate (Positive label: 1.0)')\n",
        "    ax.set_ylabel('True Positive Rate (Positive label: 1.0)')\n",
        "\n",
        "    interp_tpr = np.interp(mean_fpr, lr_fpr, lr_tpr)\n",
        "    interp_tpr[0] = 0.0\n",
        "    tprs.append(interp_tpr)\n",
        "    aucs.append(roc_auc)\n",
        "\n",
        "\n",
        "    ############ P_R Curve\n",
        "    precision, recall, _ = precision_recall_curve(y_valid, pred_proba)\n",
        "    # plot the model precision-recall curve\n",
        "    axx.plot(recall, precision, lw=1, alpha=0.3, label=r\"P_R_curve fold %d (AUC =  %0.2f)\" % (fold_number, auc(recall, precision)))\n",
        "\n",
        "    return tprs, aucs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVC8y_-Z96K9"
      },
      "outputs": [],
      "source": [
        "number_class=2\n",
        "cnn_accc_5iteration=[]\n",
        "cnn_spp_5iteration=[]\n",
        "cnn_see_5iteration=[]\n",
        "cnn_prr_5iteration=[]\n",
        "cnn_f11_5iteration=[]\n",
        "cnn_aucc_5iteration=[]\n",
        "cnn_pr_aucc_5iteration=[]\n",
        "class_acc_5iteration = np.zeros((5,number_class))\n",
        "\n",
        "\n",
        "test_accc_5iteration=[]\n",
        "test_spp_5iteration=[]\n",
        "test_see_5iteration=[]\n",
        "test_prr_5iteration=[]\n",
        "test_f11_5iteration=[]\n",
        "test_aucc_5iteration=[]\n",
        "test_pr_aucc_5iteration=[]\n",
        "class_acc_test_5iteration = np.zeros((5,number_class))\n",
        "n_iter=0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "QFU6pHxQ51BQ",
        "outputId": "2ca6ea85-f380-466c-e7a9-ad9edc2b6bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(304, 60, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature extractor for vgg16\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout\n",
        "\n",
        "def cnn_feature_extractor(input_img, n_filters=32, n_class=2):\n",
        "\n",
        "    # # Creating model\n",
        "    base_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(60, 256, 3))\n",
        "\n",
        "\n",
        "      ################## fine tune\n",
        "    # for layer in base_model.layers[:-5]:\n",
        "    #   layer.trainable = False\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential ()\n",
        "\n",
        "    model.add (base_model)\n",
        "    #flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    #model.add (Dense (16000, activation = 'relu'))\n",
        "    #model.add(Dropout(0.7))\n",
        "    #model.add (Dense (8000, activation = 'relu'))\n",
        "    #model.add(Dropout(0.3))\n",
        "    #model.add(Dense(2000, activation='relu'))\n",
        "    #model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.7))\n",
        "    ##################################\n",
        "    #################################  EFFECT OF Hidden NEURONS  ###################\n",
        "    #model.add(Dense(3544, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "VLgBVsG6x-1u"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow (x_train [270,:,:,0], cmap = 'jet')"
      ],
      "metadata": {
        "id": "a6IyC3bi6jmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary ()"
      ],
      "metadata": {
        "id": "EjzT_Y1dBpho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_test.shape"
      ],
      "metadata": {
        "id": "ybPfE9BuGtKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFAFCCYCRDl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = cnn_feature_extractor ()"
      ],
      "metadata": {
        "id": "EpdJuAQCRDpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e98e2640-50f5-4dd5-cc01-66ac8c3662d2",
        "id": "hbR00EyOvGY9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------          \n",
            " \t\t\t 1th fold \n",
            "---------------------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-dc8440d9451b>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-97ac7516f675>\u001b[0m in \u001b[0;36mcnn_feature_extractor\u001b[0;34m(input_img, n_filters, n_class)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# # Creating model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     base_model = tf.keras.applications.ResNet50(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     return ResNet(\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mstack_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pool1_pool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mstack_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstack_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstack1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"conv5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mstack1\u001b[0;34m(x, filters, blocks, stride1, name)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstacked\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstride1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_block1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         x = block1(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/resnet.py\u001b[0m in \u001b[0;36mblock1\u001b[0;34m(x, filters, kernel_size, stride, conv_shortcut, name)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_1_relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     x = layers.Conv2D(\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_2_conv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     )(x)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m   2101\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "images_train = pickle.load(open(\"/content/\" + \"train_thickness_retina.pkl\", 'rb'))\n",
        "labels_train = pickle.load(open(\"/content/\" +\"train_labels.pkl\", 'rb'))\n",
        "\n",
        "images_test = pickle.load(open(\"/content/drive/MyDrive/\" +\"test_thickness_new.pkl\", 'rb'))\n",
        "labels_test = pickle.load(open(\"/content/\" +\"test_labels.pkl\", 'rb'))\n",
        "images_test,labels_test = preparing(images_test,labels_test)\n",
        "\n",
        "images_test = np.repeat (images_test, repeats = 3, axis = 3)\n",
        "#####################################################################\n",
        "## Parameters\n",
        "#####################################################################\n",
        "channel = 3\n",
        "number_class = 2\n",
        "\n",
        "cnn_acc    = []\n",
        "cnn_se     = []\n",
        "cnn_sp     = []\n",
        "cnn_pr     = []\n",
        "cnn_f1     = []\n",
        "cnn_auc    = []\n",
        "cnn_pr_auc = []\n",
        "\n",
        "test_acc    = []\n",
        "test_se     = []\n",
        "test_sp     = []\n",
        "test_pr     = []\n",
        "test_f1     = []\n",
        "test_auc    = []\n",
        "test_pr_auc = []\n",
        "\n",
        "\n",
        "class_acc = np.zeros((number_class))\n",
        "class_acc_test = np.zeros((number_class))\n",
        "\n",
        "target_names = ['Normal' , 'MS']\n",
        "confusion_matrix = np.zeros((number_class, number_class))\n",
        "confusion_matrix_test = np.zeros((number_class, number_class))\n",
        "\n",
        "y_test = []\n",
        "tprs   = []\n",
        "aucs   = []\n",
        "y_pred = []\n",
        "x_test = {}\n",
        "\n",
        "mean_fpr  = np.linspace(0, 1, 100)\n",
        "fig, ax   = plt.subplots(figsize=(5, 5))\n",
        "fig1, ax1 = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "\n",
        "#### model parameters for vgg\n",
        "batch_size_vgg    = 8\n",
        "epoch         = 100\n",
        "filter_num    = 32\n",
        "learning_rate_vgg =  0.0004036650839061106\n",
        "\n",
        "\n",
        "\n",
        "#### model parameters for res\n",
        "batch_size_res    = 64\n",
        "epoch         = 100\n",
        "filter_num    = 32\n",
        "learning_rate_res =  0.0003494330691436937\n",
        "\n",
        "#####################################################################\n",
        "## Applying kfold\n",
        "#####################################################################\n",
        "\n",
        "nfold = 5  #please enter number of folds\n",
        "\n",
        "kf_nfold = StratifiedKFold(n_splits=nfold, random_state=None, shuffle=True)\n",
        "\n",
        "n = 0\n",
        "for train_index, val_index in kf_nfold.split(images_train,list(labels_train.values())):\n",
        "    n = n+1\n",
        "    # print(train_index, val_index)  # you can watch train and validation index using this comment\n",
        "    print(f'---------------------------------------------------------------------\\\n",
        "          \\n \\t\\t\\t {n}th fold \\n---------------------------------------------------------------------'\\\n",
        "          ,end = '\\n\\n\\n' )\n",
        "    train_index, val_index = next (skf.split (images_train, list(labels_train.values())))\n",
        "\n",
        "    x_train = {i: images_train[list(images_train.keys())[i]]  for i in train_index}\n",
        "\n",
        "    x_valid = {i: images_train[list(images_train.keys())[i]]  for i in val_index}\n",
        "\n",
        "    y_train = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "\n",
        "    y_valid = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "    x_train,y_train = preparing(x_train,y_train)\n",
        "\n",
        "    x_valid,y_valid = preparing(x_valid,y_valid)\n",
        "\n",
        "    #x_test[n] = x_valid\n",
        "    ################# Augmentation\n",
        "\n",
        "    indices = np.where(y_train == 1)[0]\n",
        "\n",
        "    x_train_ms = x_train[indices]\n",
        "    y_train_ms = y_train[indices]\n",
        "\n",
        "    x_train_ms_aug,y_train_ms_aug = Augmentation_1(x_train_ms,y_train_ms)\n",
        "\n",
        "    x_train = np.concatenate ((x_train, x_train_ms_aug), axis=0)\n",
        "    y_train = np.concatenate ((y_train, y_train_ms_aug), axis = 0)\n",
        "\n",
        "    indices = np.random.permutation (len (x_train))\n",
        "\n",
        "    x_train_shuf = x_train [indices]\n",
        "    y_train_shuf = y_train [indices]\n",
        "\n",
        "    x_train,y_train = Augmentation_2(x_train_shuf,y_train_shuf)\n",
        "\n",
        "    x_train = np.repeat (x_train, repeats = 3, axis = 3)\n",
        "\n",
        "    x_valid = np.repeat (x_valid, repeats = 3, axis = 3)\n",
        "\n",
        "    ####################################################################\n",
        "    # classification\n",
        "    ####################################################################\n",
        "\n",
        "    input_img = Input((np.shape(x_train)[1], np.shape(x_train)[2], channel))\n",
        "\n",
        "    model = cnn_feature_extractor(input_img)\n",
        "\n",
        "\n",
        "    METRICS = [\n",
        "#      keras.metrics.TruePositives(name='tp'),\n",
        "#      keras.metrics.FalsePositives(name='fp'),\n",
        "#      keras.metrics.TrueNegatives(name='tn'),\n",
        "#      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "#      keras.metrics.Precision(name='precision'),\n",
        "#      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "#      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "      ]\n",
        "\n",
        "\n",
        "    my_optimizer =  tf.keras.optimizers.Adam(lr=learning_rate_res)\n",
        "    model.compile(optimizer=my_optimizer, loss=\"binary_crossentropy\", metrics=METRICS)\n",
        "    callbacks = [EarlyStopping(patience=20, verbose=1),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "        ModelCheckpoint(f'oct{n}.h5', verbose=1, save_best_only=True, save_weights_only=True)]\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    #################################\n",
        "    ###### Applying model  ###########\n",
        "    #################################\n",
        "    results = model.fit(x_train, y_train, batch_size=batch_size_res, epochs=epoch, callbacks=callbacks,\\\n",
        "                    validation_data=(x_valid, np.asarray(y_valid, dtype=np.float64)))\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f\"Learning curve {n}th fold\")\n",
        "    plt.plot(results.history[\"loss\"][:-7], label=\"loss\")\n",
        "    plt.plot(results.history[\"val_loss\"][:-7], label=\"val_loss\")\n",
        "    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"log_loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.title(f\"Learning curve {n}th fold\")\n",
        "    plt.plot(results.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(results.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.plot( np.argmax(results.history[\"val_accuracy\"]), np.max(results.history[\"val_accuracy\"]),\\\n",
        "             marker=\"x\", color=\"r\", label=\"best accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    # load the best model\n",
        "    model.load_weights(f'oct{n}.h5')\n",
        "\n",
        "\n",
        "    pred_proba = model.predict(x_valid).ravel()\n",
        "    pred_class = (pred_proba > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "    ##### calculating metrics\n",
        "\n",
        "    cnn_acc.append(metrics.accuracy_score(y_valid, pred_class))\n",
        "    print(f'accuracy of {n}th fold : {metrics.accuracy_score(y_valid, pred_class)}')\n",
        "    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(y_valid, pred_class, pred_proba)\n",
        "\n",
        "    cnn_sp.append(SP)\n",
        "    cnn_se.append(SE)\n",
        "    cnn_pr.append(PR)\n",
        "    cnn_f1.append(f1)\n",
        "    cnn_auc.append(ROC_AUC)\n",
        "    cnn_pr_auc.append(P_R_AUC)\n",
        "\n",
        "    #################### acc for each class ##################\n",
        "    class_acc  = np.add(class_acc,Class_acc)\n",
        "\n",
        "    ###################### Total confusion_matrix for poly kernel ############\n",
        "    confusion_matrix = np.add(confusion_matrix,cm)\n",
        "\n",
        "######################## internal test\n",
        "    pred_proba_test = model.predict(images_test).ravel()\n",
        "    pred_class_test = (pred_proba_test > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "    ##### calculating metrics\n",
        "    print(f'test accuracy of {n}th fold : {metrics.accuracy_score(labels_test, pred_class_test)}')\n",
        "    SP, SE, PR, f1, ROC_AUC, P_R_AUC, Class_acc, cm = metrics_calculation(labels_test, pred_class_test, pred_proba_test)\n",
        "\n",
        "    test_acc.append(metrics.accuracy_score(labels_test, pred_class_test))\n",
        "    test_sp.append(SP)\n",
        "    test_se.append(SE)\n",
        "    test_pr.append(PR)\n",
        "    test_f1.append(f1)\n",
        "    test_auc.append(ROC_AUC)\n",
        "    test_pr_auc.append(P_R_AUC)\n",
        "\n",
        "    #################### acc for each class ##################\n",
        "    class_acc_test  = np.add(class_acc_test,Class_acc)\n",
        "\n",
        "    ###################### Total confusion_matrix for poly kernel ############\n",
        "    confusion_matrix_test = np.add(confusion_matrix_test,cm)\n",
        "\n",
        "    ###################### Ploting ROC and PR curves for each fold ############\n",
        "    y_test = np.append(y_test, y_valid, axis = 0)\n",
        "    y_pred = np.append(y_pred, pred_proba, axis = 0)\n",
        "    ###\n",
        "    tprs, aucs = fold_curves(ax, ax1, y_valid, n, mean_fpr, pred_proba, tprs, aucs)\n",
        "\n",
        "######################  the mean Ploting ROC and PR curves ############\n",
        "###\n",
        "curve_ploting(ax, ax1, mean_fpr, aucs, tprs, y_test, y_pred, 'CNN' )\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#######################################\n",
        "    # ploting confusion matrix\n",
        "#######################################\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix/nfold, display_labels=target_names)\n",
        "disp.plot()\n",
        "\n",
        "\n",
        "########################################\n",
        "#     Metrics printing\n",
        "########################################\n",
        "cnn_accc     = np.mean(cnn_acc)\n",
        "cnn_spp      = np.mean(cnn_sp)\n",
        "cnn_see      = np.mean(cnn_se)\n",
        "cnn_prr      = np.mean(cnn_pr)\n",
        "cnn_f11      = np.mean(cnn_f1)\n",
        "cnn_aucc     = np.mean(cnn_auc)\n",
        "cnn_pr_aucc  = np.mean(cnn_pr_auc)\n",
        "\n",
        "###################### internal test\n",
        "test_accc     = np.mean(test_acc)\n",
        "test_spp      = np.mean(test_sp)\n",
        "test_see      = np.mean(test_se)\n",
        "test_prr      = np.mean(test_pr)\n",
        "test_f11      = np.mean(test_f1)\n",
        "test_aucc     = np.mean(test_auc)\n",
        "test_pr_aucc  = np.mean(test_pr_auc)\n",
        "\n",
        "#################### acc for each class ##################\n",
        "class_acc  = class_acc/nfold\n",
        "class_acc_test  = class_acc_test/nfold\n",
        "\n",
        "print('cnn_acc     = %f' % cnn_accc)\n",
        "print('cnn_sp      = %f' % cnn_spp)\n",
        "print('cnn_se      = %f' % cnn_see)\n",
        "print('cnn_pr      = %f' % cnn_prr)\n",
        "print('cnn_f1      = %f' % cnn_f11)\n",
        "print('cnn_auc     = %f' % cnn_aucc)\n",
        "print('cnn_pr_auc  = %f' % cnn_pr_aucc, end='\\n\\n')\n",
        "\n",
        "\n",
        "print('acc of class %s' % target_names[0], '= %f' % class_acc[0])\n",
        "print('acc of class %s' % target_names[1], '= %f' % class_acc[1], end='\\n\\n')\n",
        "\n",
        "print('test_acc     = %f' % test_accc)\n",
        "print('test_sp      = %f' % test_spp)\n",
        "print('test_se      = %f' % test_see)\n",
        "print('test_pr      = %f' % test_prr)\n",
        "print('test_f1      = %f' % test_f11)\n",
        "print('test_auc     = %f' % test_aucc)\n",
        "print('test_pr_auc  = %f' % test_pr_aucc, end='\\n\\n')\n",
        "\n",
        "\n",
        "print('test acc of class %s' % target_names[0], '= %f' % class_acc_test[0])\n",
        "print('test acc of class %s' % target_names[1], '= %f' % class_acc_test[1], end='\\n\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7MmYLbwI2Nl",
        "outputId": "f6f9551e-c5f2-4777-b060-824117eb09a5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6052631578947368,\n",
              " 0.6052631578947368,\n",
              " 0.6052631578947368,\n",
              " 0.6052631578947368,\n",
              " 0.6052631578947368]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_acc"
      ],
      "metadata": {
        "id": "Q17VngQML192",
        "outputId": "a4953ca7-677b-405d-e032-1d0b39539274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7741935483870968,\n",
              " 0.8064516129032258,\n",
              " 0.8064516129032258,\n",
              " 0.8064516129032258,\n",
              " 0.8064516129032258]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93603208-4084-4c9c-950c-8fff40e9b662",
        "id": "H_JgMB9avGY-"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from optuna.integration import TFKerasPruningCallback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################### state of the arts ##############################\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "\n",
        "def classifier (trial):\n",
        "\n",
        "  # Load the pre-trained VGG16 model without the top (fully connected) layers\n",
        "  base_model = tf.keras.applications.VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(60,256, 3),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "  # Freeze the pre-trained layers so they are not trainable during training\n",
        "  #for layer in base_model.layers:\n",
        "    #layer.trainable = False\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  model = Sequential ()\n",
        "\n",
        "  model.add (base_model)\n",
        "\n",
        "  model.add (Flatten ())\n",
        "\n",
        "  #dropout_l0 = trial.suggest_float(\"dropout_l0\", 0, 0.7,step=0.1)\n",
        "\n",
        "  #model.add (Dropout (dropout_l0))\n",
        "\n",
        "\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "\n",
        "\n",
        "  for i in range(n_layers):\n",
        "\n",
        "\n",
        "      n_units = trial.suggest_int(\"n_units_l{}\".format(i), 16, 4096, log = True)\n",
        "\n",
        "      model.add (Dense (n_units, activation = 'relu'))\n",
        "\n",
        "      dropout = trial.suggest_float(\"dropout_l{}\".format (i), 0, 0.7,step=0.1)\n",
        "\n",
        "      model.add (Dropout (rate = dropout))\n",
        "\n",
        "  model.add (Dense (1, activation = 'sigmoid'))\n",
        "\n",
        "  lr = trial.suggest_float ('lr', 1e-5, 1e-1, log = True)\n",
        "\n",
        "  my_optimizer = tf.keras.optimizers.Adam (learning_rate= lr)\n",
        "\n",
        "\n",
        "  model.compile(optimizer=my_optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "mpxIKQ-qvGY_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = 42)\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def preparing(x, y):\n",
        "\n",
        "    data  = []\n",
        "    label = []\n",
        "    for i in x:\n",
        "        for j in range(len(x[i])):\n",
        "            data.append(np.array(x[i][j]))\n",
        "            label.append(y[i])\n",
        "            #img = resize (x[i][j], (224, 224, 1), mode = 'constant', preserve_range= True)\n",
        "            #data.append (img)\n",
        "            #label.append (y [i])\n",
        "\n",
        "\n",
        "    data = np.reshape(data, np.shape(data))\n",
        "    return data, np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def objective (trial):\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "  rotation_range= 5, # rotation\n",
        "  zoom_range = 0.1,\n",
        "  fill_mode='nearest',\n",
        "  data_format='channels_last',\n",
        "    )\n",
        "\n",
        "  datagen2 = ImageDataGenerator(\n",
        "  #rotation_range= 5, # rotation\n",
        "  width_shift_range= [-30, 30], # horizontal shift\n",
        "  #height_shift_range= [-5, 5] , # vertical shift\n",
        "  zoom_range= 0.2,\n",
        "  vertical_flip= True , # vertical flip\n",
        "  #brightness_range= [0.2, 1.5]\n",
        "    )\n",
        "\n",
        "\n",
        "  images_train = pickle.load(open(\"/content/\"+\"train_thickness_retina.pkl\", 'rb'))\n",
        "  labels_train = pickle.load(open(\"/content/\"+\"train_labels.pkl\", 'rb'))\n",
        "\n",
        "  train_index, val_index = next (skf.split (images_train, list(labels_train.values())))\n",
        "\n",
        "  x_train = {i: images_train[list(images_train.keys())[i]]  for i in train_index}\n",
        "\n",
        "  x_valid = {i: images_train[list(images_train.keys())[i]]  for i in val_index}\n",
        "\n",
        "  y_train = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "\n",
        "  y_valid = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "  x_train,y_train = preparing(x_train,y_train)\n",
        "\n",
        "  x_valid,y_valid = preparing(x_valid,y_valid)\n",
        "\n",
        "\n",
        "  #rotation_angle  = trial.suggest_float(\"rotation_angle\", 0, 40, step = 10)\n",
        "  #zoom_range = trial.suggest_float(\"zoom_range\", 0, 0.5, step = 0.1)\n",
        "\n",
        "  #color_jitter_brightness = trial.suggest_float (\"color_jitter_brightness\", 0.1, 0.8, step = 0.1)\n",
        "  #shift_horizontal = trial.suggest_uniform(\"shift_horizontal\", 0, 0.7)\n",
        "  #shift_vertical = trial.suggest_uniform(\"shift_vertical\", 0, 0.7)\n",
        "  #vertical_flip_prob = trial.suggest_float (\"vertical_flip_prob\", 0, 1, step = 0.1)\n",
        "\n",
        "  indices = np.where(y_train == 1)[0]\n",
        "\n",
        "  x_train_ms = x_train[indices]\n",
        "  y_train_ms = y_train[indices]\n",
        "  #################Augmentation##################################\n",
        "\n",
        "  # First Augmentation\n",
        "\n",
        "  x_train_ms_aug =np.zeros_like(x_train_ms, dtype=np.float32)\n",
        "\n",
        "  y_train_ms_aug =np.zeros_like(y_train_ms, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_ms)):\n",
        "\n",
        "    x1= x_train_ms[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_ms_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_ms_aug [i] = y_train[i]\n",
        "\n",
        "  x_train = np.concatenate ((x_train, x_train_ms_aug), axis=0)\n",
        "  y_train = np.concatenate ((y_train, y_train_ms_aug), axis = 0)\n",
        "\n",
        "  indices = np.random.permutation (len (x_train))\n",
        "\n",
        "  x_train_shuf = x_train [indices]\n",
        "  y_train_shuf = y_train [indices]\n",
        "\n",
        "  # Second Augmentation\n",
        "\n",
        "  x_train_aug =np.zeros_like(x_train_shuf, dtype=np.float32)\n",
        "\n",
        "  y_train_aug =np.zeros_like(y_train_shuf, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_aug)):\n",
        "\n",
        "    x1= x_train_aug[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen2.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_aug [i] = y_train[i]\n",
        "\n",
        "    x_train = np.concatenate ((x_train_shuf, x_train_aug), axis=0)\n",
        "    y_train = np.concatenate ((y_train_shuf, y_train_aug), axis = 0)\n",
        "\n",
        "\n",
        "  ###############################################################################33\n",
        "\n",
        "\n",
        "  x_train = np.repeat (x_train, repeats = 3, axis = 3)\n",
        "\n",
        "  x_valid = np.repeat (x_valid, repeats = 3, axis = 3)\n",
        "        ####################################################################\n",
        "        # classification via my model\n",
        "        ####################################################################\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128])\n",
        "\n",
        "  model = classifier (trial)\n",
        "\n",
        "\n",
        "  # Generate our trial model.\n",
        "\n",
        "\n",
        "  model.fit(x_train,\n",
        "            np.asarray(y_train, dtype=np.float64),\n",
        "            batch_size= batch_size,\n",
        "            epochs=50,\n",
        "            callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\"), EarlyStopping(patience=20, verbose=1),\n",
        "            ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "            ModelCheckpoint(f'slo.h5', verbose=1, save_best_only=True, save_weights_only=True)],\n",
        "            validation_data=(x_valid, np.asarray(y_valid, dtype=np.float64)),\n",
        "            )\n",
        "  model.load_weights(f'slo.h5')\n",
        "  score = model.evaluate (x_valid, np.asarray(y_valid, dtype=np.float64), verbose = 1)\n",
        "\n",
        "  return score [1]\n"
      ],
      "metadata": {
        "id": "KhGw92auvGY_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9998b956-a716-4bb3-be4f-463594e6abeb",
        "id": "JchBxE8tvGZA"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-26 20:38:52,916] A new study created in memory with name: no-name-070cbeee-7c3f-4c75-be97-a16583c34122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 2s 0us/step\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-02-26 20:39:08,983] Trial 0 failed with parameters: {'batch_size': 128, 'n_layers': 2, 'n_units_l0': 89, 'dropout_l0': 0.2, 'n_units_l1': 3393, 'dropout_l1': 0.30000000000000004, 'lr': 0.09109842838816161} because of the following error: ResourceExhaustedError().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-45-a31a826af90a>\", line 148, in objective\n",
            "    model.fit(x_train,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:\n",
            "\n",
            "Detected at node sequential/vgg16/block1_conv2/Relu defined at (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "\n",
            "  File \"<ipython-input-46-71d9bb1b13ff>\", line 3, in <cell line: 3>\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\", line 451, in optimize\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "\n",
            "  File \"<ipython-input-45-a31a826af90a>\", line 148, in objective\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n",
            "\n",
            "OOM when allocating tensor with shape[128,64,60,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
            "\t [[{{node sequential/vgg16/block1_conv2/Relu}}]]\n",
            "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
            " [Op:__inference_train_function_164886]\n",
            "[W 2024-02-26 20:39:08,985] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node sequential/vgg16/block1_conv2/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-46-71d9bb1b13ff>\", line 3, in <cell line: 3>\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\", line 451, in optimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 66, in _optimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n\n  File \"<ipython-input-45-a31a826af90a>\", line 148, in objective\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[128,64,60,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/vgg16/block1_conv2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_164886]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-71d9bb1b13ff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-a31a826af90a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m   model.fit(x_train,\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node sequential/vgg16/block1_conv2/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-46-71d9bb1b13ff>\", line 3, in <cell line: 3>\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\", line 451, in optimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 66, in _optimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n\n  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n\n  File \"<ipython-input-45-a31a826af90a>\", line 148, in objective\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5395, in relu\n\nOOM when allocating tensor with shape[128,64,60,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/vgg16/block1_conv2/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_164886]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myw09Hadgqz1",
        "outputId": "3435b2bb-d5b2-46da-cd4c-ca209c85b094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "55CwNaKQvGZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/train_thickness_retina_iran.zip"
      ],
      "metadata": {
        "id": "Abghu8jri54J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/test_thickness_retina_iran.zip"
      ],
      "metadata": {
        "id": "FGd1V92Djg1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF1IO0ku538H"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from optuna.integration import TFKerasPruningCallback"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################### state of the arts ##############################\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "\n",
        "def classifier (trial):\n",
        "\n",
        "  # Load the pre-trained VGG16 model without the top (fully connected) layers\n",
        "  base_model = tf.keras.applications.ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(128, 128, 3),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "  # Freeze the pre-trained layers so they are not trainable during training\n",
        "  #for layer in base_model.layers:\n",
        "    #layer.trainable = False\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  model = Sequential ()\n",
        "\n",
        "  model.add (base_model)\n",
        "\n",
        "  model.add (Flatten ())\n",
        "\n",
        "  #dropout_l0 = trial.suggest_float(\"dropout_l0\", 0, 0.7,step=0.1)\n",
        "\n",
        "  #model.add (Dropout (dropout_l0))\n",
        "\n",
        "\n",
        "  n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "\n",
        "\n",
        "  for i in range(n_layers):\n",
        "\n",
        "\n",
        "      n_units = trial.suggest_int(\"n_units_l{}\".format(i), 16, 4096, log = True)\n",
        "\n",
        "      model.add (Dense (n_units, activation = 'relu'))\n",
        "\n",
        "      dropout = trial.suggest_float(\"dropout_l{}\".format (i), 0, 0.7,step=0.1)\n",
        "\n",
        "      model.add (Dropout (rate = dropout))\n",
        "\n",
        "  model.add (Dense (1, activation = 'sigmoid'))\n",
        "\n",
        "  lr = trial.suggest_float ('lr', 1e-5, 1e-3, log = True)\n",
        "\n",
        "  my_optimizer = tf.keras.optimizers.Adam (learning_rate= lr)\n",
        "\n",
        "\n",
        "  model.compile(optimizer=my_optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5C-nyGvz57Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = 42)\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def preparing(x, y):\n",
        "\n",
        "    data  = []\n",
        "    label = []\n",
        "    for i in x:\n",
        "        for j in range(len(x[i])):\n",
        "\n",
        "            #data.append(np.array(x[i][j]))\n",
        "            #label.append(y[i])\n",
        "\n",
        "            img = resize (x[i][j], (128, 128, 1), mode = 'constant', preserve_range= True)\n",
        "            data.append (img)\n",
        "            label.append (y [i])\n",
        "\n",
        "    data = np.reshape(data, np.shape(data))\n",
        "    return data, np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def objective (trial):\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "  rotation_range= 5, # rotation\n",
        "  zoom_range = 0.1,\n",
        "  fill_mode='nearest',\n",
        "  data_format='channels_last',\n",
        "    )\n",
        "\n",
        "  datagen2 = ImageDataGenerator(\n",
        "  #rotation_range= 5, # rotation\n",
        "  width_shift_range= [-30, 30], # horizontal shift\n",
        "  #height_shift_range= [-5, 5] , # vertical shift\n",
        "  zoom_range= 0.2,\n",
        "  vertical_flip= True , # vertical flip\n",
        "  #brightness_range= [0.2, 1.5]\n",
        "    )\n",
        "\n",
        "\n",
        "  images_train = pickle.load(open(\"/content/\"+\"train_thickness_retina.pkl\", 'rb'))\n",
        "  labels_train = pickle.load(open(\"/content/\"+\"train_labels.pkl\", 'rb'))\n",
        "\n",
        "  train_index, val_index = next (skf.split (images_train, list(labels_train.values())))\n",
        "\n",
        "  x_train = {i: images_train[list(images_train.keys())[i]]  for i in train_index}\n",
        "\n",
        "  x_valid = {i: images_train[list(images_train.keys())[i]]  for i in val_index}\n",
        "\n",
        "  y_train = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "\n",
        "  y_valid = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "  x_train,y_train = preparing(x_train,y_train)\n",
        "\n",
        "  x_valid,y_valid = preparing(x_valid,y_valid)\n",
        "\n",
        "\n",
        "  #rotation_angle  = trial.suggest_float(\"rotation_angle\", 0, 40, step = 10)\n",
        "  #zoom_range = trial.suggest_float(\"zoom_range\", 0, 0.5, step = 0.1)\n",
        "\n",
        "  #color_jitter_brightness = trial.suggest_float (\"color_jitter_brightness\", 0.1, 0.8, step = 0.1)\n",
        "  #shift_horizontal = trial.suggest_uniform(\"shift_horizontal\", 0, 0.7)\n",
        "  #shift_vertical = trial.suggest_uniform(\"shift_vertical\", 0, 0.7)\n",
        "  #vertical_flip_prob = trial.suggest_float (\"vertical_flip_prob\", 0, 1, step = 0.1)\n",
        "\n",
        "  indices = np.where(y_train == 1)[0]\n",
        "\n",
        "  x_train_ms = x_train[indices]\n",
        "  y_train_ms = y_train[indices]\n",
        "  #################Augmentation##################################\n",
        "\n",
        "  # First Augmentation\n",
        "\n",
        "  x_train_ms_aug =np.zeros_like(x_train_ms, dtype=np.float32)\n",
        "\n",
        "  y_train_ms_aug =np.zeros_like(y_train_ms, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_ms)):\n",
        "\n",
        "    x1= x_train_ms[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_ms_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_ms_aug [i] = y_train[i]\n",
        "\n",
        "  x_train = np.concatenate ((x_train, x_train_ms_aug), axis=0)\n",
        "  y_train = np.concatenate ((y_train, y_train_ms_aug), axis = 0)\n",
        "\n",
        "  indices = np.random.permutation (len (x_train))\n",
        "\n",
        "  x_train_shuf = x_train [indices]\n",
        "  y_train_shuf = y_train [indices]\n",
        "\n",
        "  # Second Augmentation\n",
        "\n",
        "  x_train_aug =np.zeros_like(x_train_shuf, dtype=np.float32)\n",
        "\n",
        "  y_train_aug =np.zeros_like(y_train_shuf, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_aug)):\n",
        "\n",
        "    x1= x_train_aug[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen2.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_aug [i] = y_train[i]\n",
        "\n",
        "    x_train = np.concatenate ((x_train_shuf, x_train_aug), axis=0)\n",
        "    y_train = np.concatenate ((y_train_shuf, y_train_aug), axis = 0)\n",
        "\n",
        "\n",
        "  ###############################################################################33\n",
        "\n",
        "\n",
        "  x_train = np.repeat (x_train, repeats = 3, axis = 3)\n",
        "\n",
        "  x_valid = np.repeat (x_valid, repeats = 3, axis = 3)\n",
        "        ####################################################################\n",
        "        # classification via my model\n",
        "        ####################################################################\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128])\n",
        "\n",
        "  model = classifier (trial)\n",
        "\n",
        "\n",
        "  # Generate our trial model.\n",
        "\n",
        "\n",
        "  model.fit(x_train,\n",
        "            np.asarray(y_train, dtype=np.float64),\n",
        "            batch_size= batch_size,\n",
        "            epochs=50,\n",
        "            callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\"), #EarlyStopping(patience=10, verbose=1),\n",
        "            ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "            ModelCheckpoint(f'slo.h5', verbose=1, save_best_only=True, save_weights_only=True)],\n",
        "            validation_data=(x_valid, np.asarray(y_valid, dtype=np.float64)),\n",
        "            )\n",
        "  model.load_weights(f'slo.h5')\n",
        "  score = model.evaluate (x_valid, np.asarray(y_valid, dtype=np.float64), verbose = 1)\n",
        "\n",
        "  return score [1]\n"
      ],
      "metadata": {
        "id": "0E4-P-X857V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "7s09LdTP57YR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "12cd69e0-4d79-4fac-c59e-ff3e8b493c2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'optuna' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-71d9bb1b13ff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "Fxyq_j5Q2-f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFwjWa-eQFQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qmLlmRflQG61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHmrmbMJQG9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SELSRZwVQHAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier (trial):\n",
        "\n",
        "  model = Sequential ()\n",
        "\n",
        "  num_conv_blocks = trial.suggest_int(\"num_conv_blocks\", 1, 3)\n",
        "\n",
        "  model = Sequential()\n",
        "  input_img = Input((60, 256, 1))\n",
        "  n_filters_1 = trial.suggest_categorical(\"n_filters_1\", [8, 16, 32, 64])\n",
        "  #print(f'n_filters = {n_filters}')\n",
        "\n",
        "  model.add(Conv2D(n_filters_1, kernel_size=3, activation='relu',input_shape=input_img.shape[1:], padding='same'))\n",
        "  model.add(MaxPool2D(2, 2))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  #n_filters_2 = trial.suggest_categorical(\"n_filters_2\", [8, 16, 32, 64, 128])\n",
        "\n",
        "  #model.add(Conv2D(n_filters_2, kernel_size=3, activation='relu',input_shape=input_img.shape[1:], padding='same'))\n",
        "  #model.add(MaxPool2D(2, 2))\n",
        "  #model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  #for i in range(1,num_conv_blocks):\n",
        "\n",
        "    #num_filter = trial.suggest_categorical ('num_filter_l{}'.format (i), [16, 32, 64, 128])\n",
        "    #model.add (Conv2D (num_filter, kernel_size = 3, activation = 'relu', input_shape = (60, 256, 1), padding = 'same'))\n",
        "    #model.add (MaxPool2D (2, 2))\n",
        "    #model.add (BatchNormalization ())\n",
        "\n",
        "  model.add (Flatten ())\n",
        "\n",
        "  num_layers = trial.suggest_int ('num_layers', 1, 5)\n",
        "\n",
        "  for j in range (num_layers):\n",
        "\n",
        "    n_units = trial.suggest_int(\"n_units_l{}\".format(j), 16, 4096, log = True)\n",
        "\n",
        "    model.add (Dense (n_units, activation = 'relu'))\n",
        "\n",
        "    dropout = trial.suggest_float(\"dropout_l{}\".format (j), 0, 0.7,step=0.1)\n",
        "\n",
        "    model.add (Dropout (rate = dropout))\n",
        "\n",
        "  model.add (Dense (1, activation = 'sigmoid'))\n",
        "\n",
        "  lr = trial.suggest_float ('lr', 1e-5, 1e-3, log = True)\n",
        "\n",
        "  my_optimizer = tf.keras.optimizers.Adam (learning_rate= lr)\n",
        "\n",
        "  model.compile(optimizer=my_optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "mFFMZWwXIy33"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = None)\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def preparing(x, y):\n",
        "\n",
        "    data  = []\n",
        "    label = []\n",
        "    for i in x:\n",
        "        for j in range(len(x[i])):\n",
        "            data.append(np.array(x[i][j]))\n",
        "            #data.append (resize (x [i] [j], (128, 128, 1), mode = 'constant', preserve_range = True))\n",
        "            label.append(y[i])\n",
        "\n",
        "\n",
        "    data = np.reshape(data, np.shape(data))\n",
        "    return data, np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def objective (trial):\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "  rotation_range= 5, # rotation\n",
        "  zoom_range =0.1,\n",
        "  fill_mode='nearest',\n",
        "  data_format='channels_last',\n",
        "    )\n",
        "\n",
        "  datagen2 = ImageDataGenerator(\n",
        "  #rotation_range= 5, # rotation\n",
        "  width_shift_range= [-30, 30], # horizontal shift\n",
        "  #height_shift_range= [-5, 5] , # vertical shift\n",
        "  zoom_range= 0.2,\n",
        "  vertical_flip= True , # vertical flip\n",
        "  #brightness_range= [0.2, 1.5]\n",
        "    )\n",
        "\n",
        "\n",
        "  images_train = pickle.load(open(\"/content/\"+\"train_thickness_retina.pkl\", 'rb'))\n",
        "  labels_train = pickle.load(open(\"/content/\"+\"train_labels.pkl\", 'rb'))\n",
        "\n",
        "  train_index, val_index = next (skf.split (images_train, list(labels_train.values())))\n",
        "\n",
        "  x_train = {i: images_train[list(images_train.keys())[i]]  for i in train_index}\n",
        "\n",
        "  x_valid = {i: images_train[list(images_train.keys())[i]]  for i in val_index}\n",
        "\n",
        "  y_train = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "\n",
        "  y_valid = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "  x_train,y_train = preparing(x_train,y_train)\n",
        "\n",
        "  x_valid,y_valid = preparing(x_valid,y_valid)\n",
        "\n",
        "\n",
        "  #rotation_angle  = trial.suggest_float(\"rotation_angle\", 0, 40, step = 10)\n",
        "  #zoom_range = trial.suggest_float(\"zoom_range\", 0, 0.5, step = 0.1)\n",
        "\n",
        "  #color_jitter_brightness = trial.suggest_float (\"color_jitter_brightness\", 0.1, 0.8, step = 0.1)\n",
        "  #shift_horizontal = trial.suggest_uniform(\"shift_horizontal\", 0, 0.7)\n",
        "  #shift_vertical = trial.suggest_uniform(\"shift_vertical\", 0, 0.7)\n",
        "  #vertical_flip_prob = trial.suggest_float (\"vertical_flip_prob\", 0, 1, step = 0.1)\n",
        "\n",
        "  indices = np.where(y_train == 1)[0]\n",
        "\n",
        "  x_train_ms = x_train[indices]\n",
        "  y_train_ms = y_train[indices]\n",
        "  #################Augmentation##################################\n",
        "\n",
        "  # First Augmentation\n",
        "\n",
        "  x_train_ms_aug =np.zeros_like(x_train_ms, dtype=np.float32)\n",
        "\n",
        "  y_train_ms_aug =np.zeros_like(y_train_ms, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_ms)):\n",
        "\n",
        "    x1= x_train_ms[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_ms_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_ms_aug [i] = y_train[i]\n",
        "\n",
        "  x_train = np.concatenate ((x_train, x_train_ms_aug), axis=0)\n",
        "  y_train = np.concatenate ((y_train, y_train_ms_aug), axis = 0)\n",
        "\n",
        "  indices = np.random.permutation (len (x_train))\n",
        "\n",
        "  x_train_shuf = x_train [indices]\n",
        "  y_train_shuf = y_train [indices]\n",
        "\n",
        "  # Second Augmentation\n",
        "\n",
        "  x_train_aug =np.zeros_like(x_train_shuf, dtype=np.float32)\n",
        "\n",
        "  y_train_aug =np.zeros_like(y_train_shuf, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_aug)):\n",
        "\n",
        "    x1= x_train_aug[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen2.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_aug [i] = y_train[i]\n",
        "\n",
        "    x_train = np.concatenate ((x_train_shuf, x_train_aug), axis=0)\n",
        "    y_train = np.concatenate ((y_train_shuf, y_train_aug), axis = 0)\n",
        "\n",
        "\n",
        "  ###############################################################################33\n",
        "\n",
        "\n",
        "  #x_train = np.repeat (x_train, repeats = 3, axis = 3)\n",
        "\n",
        "  #x_valid = np.repeat (x_valid, repeats = 3, axis = 3)\n",
        "        ####################################################################\n",
        "        # classification via my model\n",
        "        ####################################################################\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128])\n",
        "\n",
        "  model = classifier (trial)\n",
        "\n",
        "\n",
        "  # Generate our trial model.\n",
        "\n",
        "\n",
        "  model.fit(x_train,\n",
        "            np.asarray(y_train, dtype=np.float64),\n",
        "            batch_size= batch_size,\n",
        "            epochs=50,\n",
        "            callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\"), EarlyStopping(patience=10, verbose=1),\n",
        "            ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "            ModelCheckpoint(f'slo.h5', verbose=1, save_best_only=True, save_weights_only=True)],\n",
        "            validation_data=(x_valid, np.asarray(y_valid, dtype=np.float64)),\n",
        "            )\n",
        "  model.load_weights(f'slo.h5')\n",
        "  score = model.evaluate (x_valid, np.asarray(y_valid, dtype=np.float64), verbose = 1)\n",
        "\n",
        "  return score [1]\n"
      ],
      "metadata": {
        "id": "anpfy1hrIy60"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "id": "fOvpRl7Jh9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e83fb92-abd9-4b57-b16c-1c3f077b6a66"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-26 20:36:09,482] A new study created in memory with name: no-name-6d9735b4-54fc-478b-95f9-ce04220f389c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.8444 - accuracy: 0.5234\n",
            "Epoch 1: val_loss improved from inf to 0.67370, saving model to slo.h5\n",
            "5/5 [==============================] - 2s 132ms/step - loss: 2.5465 - accuracy: 0.5327 - val_loss: 0.6737 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 2/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6973 - accuracy: 0.5742\n",
            "Epoch 2: val_loss improved from 0.67370 to 0.65823, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 0.6712 - accuracy: 0.5915 - val_loss: 0.6582 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 3/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.5686 - accuracy: 0.7148\n",
            "Epoch 3: val_loss did not improve from 0.65823\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.5818 - accuracy: 0.6961 - val_loss: 0.7238 - val_accuracy: 0.3000 - lr: 1.5075e-04\n",
            "Epoch 4/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6899 - accuracy: 0.6523\n",
            "Epoch 4: val_loss did not improve from 0.65823\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.6694 - accuracy: 0.6634 - val_loss: 0.9063 - val_accuracy: 0.3000 - lr: 1.5075e-04\n",
            "Epoch 5/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.8580 - accuracy: 0.6250\n",
            "Epoch 5: val_loss improved from 0.65823 to 0.57441, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 0.8625 - accuracy: 0.6209 - val_loss: 0.5744 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 6/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6709 - accuracy: 0.6523\n",
            "Epoch 6: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 0.6513 - accuracy: 0.6699 - val_loss: 0.7445 - val_accuracy: 0.3333 - lr: 1.5075e-04\n",
            "Epoch 7/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.6265 - accuracy: 0.6719\n",
            "Epoch 7: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.6161 - accuracy: 0.6732 - val_loss: 0.5961 - val_accuracy: 0.8667 - lr: 1.5075e-04\n",
            "Epoch 8/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.5423 - accuracy: 0.6992\n",
            "Epoch 8: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5318 - accuracy: 0.7059 - val_loss: 0.6573 - val_accuracy: 0.5667 - lr: 1.5075e-04\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.6961\n",
            "Epoch 9: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5527 - accuracy: 0.6961 - val_loss: 0.6525 - val_accuracy: 0.6000 - lr: 1.5075e-04\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.7255\n",
            "Epoch 10: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5335 - accuracy: 0.7255 - val_loss: 0.5786 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.7190\n",
            "Epoch 11: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.5131 - accuracy: 0.7190 - val_loss: 0.6254 - val_accuracy: 0.8000 - lr: 1.5075e-04\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.7451\n",
            "Epoch 12: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.4705 - accuracy: 0.7451 - val_loss: 0.5803 - val_accuracy: 0.8000 - lr: 1.5075e-04\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.7451\n",
            "Epoch 13: val_loss did not improve from 0.57441\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4690 - accuracy: 0.7451 - val_loss: 0.6097 - val_accuracy: 0.8333 - lr: 1.5075e-04\n",
            "Epoch 14/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4603 - accuracy: 0.7422\n",
            "Epoch 14: val_loss improved from 0.57441 to 0.56011, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.4689 - accuracy: 0.7386 - val_loss: 0.5601 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4774 - accuracy: 0.7353\n",
            "Epoch 15: val_loss did not improve from 0.56011\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.4774 - accuracy: 0.7353 - val_loss: 0.5943 - val_accuracy: 0.8667 - lr: 1.5075e-04\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.7353\n",
            "Epoch 16: val_loss improved from 0.56011 to 0.55898, saving model to slo.h5\n",
            "5/5 [==============================] - 2s 458ms/step - loss: 0.4676 - accuracy: 0.7353 - val_loss: 0.5590 - val_accuracy: 0.8667 - lr: 1.5075e-04\n",
            "Epoch 17/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4718 - accuracy: 0.7266\n",
            "Epoch 17: val_loss improved from 0.55898 to 0.54225, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 118ms/step - loss: 0.4603 - accuracy: 0.7418 - val_loss: 0.5423 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 18/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4184 - accuracy: 0.7812\n",
            "Epoch 18: val_loss did not improve from 0.54225\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4396 - accuracy: 0.7680 - val_loss: 0.5513 - val_accuracy: 0.7667 - lr: 1.5075e-04\n",
            "Epoch 19/50\n",
            "3/5 [=================>............] - ETA: 0s - loss: 0.4039 - accuracy: 0.7865\n",
            "Epoch 19: val_loss did not improve from 0.54225\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4229 - accuracy: 0.7745 - val_loss: 0.5427 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 20/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4315 - accuracy: 0.7539\n",
            "Epoch 20: val_loss improved from 0.54225 to 0.53164, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 108ms/step - loss: 0.4232 - accuracy: 0.7647 - val_loss: 0.5316 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 21/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4123 - accuracy: 0.7852\n",
            "Epoch 21: val_loss improved from 0.53164 to 0.52711, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 106ms/step - loss: 0.4141 - accuracy: 0.7712 - val_loss: 0.5271 - val_accuracy: 0.7667 - lr: 1.5075e-04\n",
            "Epoch 22/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4099 - accuracy: 0.7734\n",
            "Epoch 22: val_loss improved from 0.52711 to 0.52507, saving model to slo.h5\n",
            "5/5 [==============================] - 3s 673ms/step - loss: 0.4186 - accuracy: 0.7680 - val_loss: 0.5251 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 23/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4387 - accuracy: 0.7539\n",
            "Epoch 23: val_loss did not improve from 0.52507\n",
            "5/5 [==============================] - 0s 28ms/step - loss: 0.4272 - accuracy: 0.7647 - val_loss: 0.5337 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 24/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4229 - accuracy: 0.7656\n",
            "Epoch 24: val_loss did not improve from 0.52507\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4162 - accuracy: 0.7745 - val_loss: 0.5391 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 25/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4111 - accuracy: 0.7773\n",
            "Epoch 25: val_loss improved from 0.52507 to 0.51846, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 0.4274 - accuracy: 0.7680 - val_loss: 0.5185 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 26/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4197 - accuracy: 0.7500\n",
            "Epoch 26: val_loss improved from 0.51846 to 0.50433, saving model to slo.h5\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 0.4132 - accuracy: 0.7647 - val_loss: 0.5043 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 27/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4255 - accuracy: 0.7617\n",
            "Epoch 27: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 0.4174 - accuracy: 0.7680 - val_loss: 0.5455 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 28/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4349 - accuracy: 0.7500\n",
            "Epoch 28: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.4370 - accuracy: 0.7484 - val_loss: 0.5069 - val_accuracy: 0.7333 - lr: 1.5075e-04\n",
            "Epoch 29/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4227 - accuracy: 0.7578\n",
            "Epoch 29: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.4171 - accuracy: 0.7647 - val_loss: 0.5442 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 30/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.4130 - accuracy: 0.7734\n",
            "Epoch 30: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 26ms/step - loss: 0.4023 - accuracy: 0.7810 - val_loss: 0.5529 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 31/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.3916 - accuracy: 0.7773\n",
            "Epoch 31: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3917 - accuracy: 0.7745 - val_loss: 0.5195 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 32/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.3868 - accuracy: 0.7812\n",
            "Epoch 32: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3878 - accuracy: 0.7810 - val_loss: 0.5523 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 33/50\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 0.3830 - accuracy: 0.7891\n",
            "Epoch 33: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3763 - accuracy: 0.7941 - val_loss: 0.5237 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.7876\n",
            "Epoch 34: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3723 - accuracy: 0.7876 - val_loss: 0.5522 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.7876\n",
            "Epoch 35: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.3809 - accuracy: 0.7876 - val_loss: 0.5664 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.7941\n",
            "Epoch 36: val_loss did not improve from 0.50433\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.3701 - accuracy: 0.7941 - val_loss: 0.5217 - val_accuracy: 0.7000 - lr: 1.5075e-04\n",
            "Epoch 36: early stopping\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5043 - accuracy: 0.7333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-26 20:36:24,742] Trial 0 finished with value: 0.7333333492279053 and parameters: {'batch_size': 64, 'num_conv_blocks': 1, 'n_filters_1': 16, 'num_layers': 2, 'n_units_l0': 295, 'dropout_l0': 0.0, 'n_units_l1': 23, 'dropout_l1': 0.0, 'lr': 0.00015074763713231879}. Best is trial 0 with value: 0.7333333492279053.\n",
            "[W 2024-02-26 20:36:36,175] Trial 1 failed with parameters: {'batch_size': 8, 'num_conv_blocks': 2, 'n_filters_1': 16, 'num_layers': 5, 'n_units_l0': 2425} because of the following error: ResourceExhaustedError().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-41-3fad2719ef3f>\", line 140, in objective\n",
            "    model = classifier (trial)\n",
            "  File \"<ipython-input-39-becbd248e2bd>\", line 38, in classifier\n",
            "    model.add (Dense (n_units, activation = 'relu'))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\", line 204, in _method_wrapper\n",
            "    result = method(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2100, in random_uniform\n",
            "    return tf.random.stateless_uniform(\n",
            "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: \n",
            "[W 2024-02-26 20:36:36,177] Trial 1 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-71d9bb1b13ff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-3fad2719ef3f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-becbd248e2bd>\u001b[0m in \u001b[0;36mclassifier\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mn_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_units_l{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout_l{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m                 \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateless_fold_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m   2101\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                 \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "TEjYNByGh9c-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}