{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliaghababaee/SLO_Asieh/blob/main/Copy_of_Optuna_merged.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ85iUmg7jY2",
        "outputId": "09124689-3597-47dc-a4b4-9ec790e6e6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q89MeogL7k5-",
        "outputId": "f8c62e57-3d05-4e75-ff4f-0ef1e4d6ea32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF1IO0ku538H",
        "outputId": "1abc32aa-9107-4eb8-8fc7-e7612f4aa505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Requirement already satisfied: optuna-integration in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (from optuna-integration) (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "from optuna.integration import TFKerasPruningCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C-nyGvz57Tp"
      },
      "outputs": [],
      "source": [
        "####################### state of the arts ##############################\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "\n",
        "def classifier (trial):\n",
        "\n",
        "    ### SLO model\n",
        "    slo_model =  tf.keras.applications.VGG19(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(128,128,3),\n",
        "        )\n",
        "\n",
        "    slo_model.get_layer(index = 0)._name = 'SLO'\n",
        "\n",
        "    for layer in slo_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    ### OCT model\n",
        "\n",
        "    oct_model =  tf.keras.applications.VGG16(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(60,256,3),\n",
        "        )\n",
        "\n",
        "    oct_model.get_layer(index = 0)._name = 'OCT'\n",
        "\n",
        "    for layer in oct_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "\n",
        "    inputs_slo = tf.keras.layers.Input((128,128,3))\n",
        "    slo_output = tf.keras.layers.Flatten()(slo_model(inputs_slo))\n",
        "\n",
        "\n",
        "    inputs_oct = tf.keras.layers.Input((60,256,3))\n",
        "    oct_output = tf.keras.layers.Flatten()(oct_model(inputs_oct))\n",
        "\n",
        "\n",
        "    model = tf.keras.layers.Concatenate(axis=-1)([slo_output, oct_output])\n",
        "\n",
        "\n",
        "    dropout_l0 = trial.suggest_float(\"dropout_l0\", 0, 0.7,step=0.1)\n",
        "\n",
        "    model = tf.keras.layers.Dropout(dropout_l0)(model)\n",
        "\n",
        "\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
        "\n",
        "\n",
        "    for i in range(n_layers):\n",
        "\n",
        "        n_units = trial.suggest_int(\"n_units_l{}\".format(i), 8, 4096, log = True)\n",
        "\n",
        "        model = tf.keras.layers.Dense(n_units, activation = 'relu')(model)\n",
        "\n",
        "        dropout = trial.suggest_float(\"dropout_l{}\".format (i), 0, 0.7,step=0.1)\n",
        "\n",
        "        model = tf.keras.layers.Dropout(rate = dropout)(model)\n",
        "\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(model)\n",
        "\n",
        "    lr = trial.suggest_float ('lr', 1e-5, 1e-3, log = True)\n",
        "\n",
        "    my_optimizer = tf.keras.optimizers.Adam (learning_rate= lr)\n",
        "\n",
        "    model_merged = tf.keras.Model([inputs_slo, inputs_oct] , outputs)\n",
        "\n",
        "\n",
        "    model_merged.compile(optimizer=my_optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "    return model_merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E4-P-X857V_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold (n_splits = 5, shuffle = True, random_state = 42)\n",
        "import keras\n",
        "import pickle\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def preparing(x, y):\n",
        "\n",
        "    data_slo  = []\n",
        "    data_oct  = []\n",
        "    label     = []\n",
        "    for i in x:\n",
        "      for j in range(len(x[i])):\n",
        "          data_slo.append(np.array(x[i][j][0])/255)\n",
        "          data_oct.append(np.array(x[i][j][1])*255)\n",
        "          label.append(y[i])\n",
        "    data_slo = np.reshape(data_slo, np.shape(data_slo))\n",
        "    data_oct = np.reshape(data_oct, np.shape(data_oct))\n",
        "    return data_slo, data_oct, np.array(label)\n",
        "\n",
        "\n",
        "\n",
        "def objective (trial):\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "\n",
        "##################??????????????????????????????????????????????\n",
        "\n",
        "  datagen_oct = ImageDataGenerator(\n",
        "  rotation_range= 5, # rotation\n",
        "  zoom_range= 0.2,\n",
        "  vertical_flip= True , # vertical fli\n",
        "  fill_mode='constant',\n",
        "  data_format='channels_last',\n",
        "  cval=0,\n",
        "    )\n",
        "\n",
        "  datagen_slo = ImageDataGenerator(\n",
        "  rotation_range= 5, # rotation\n",
        "  width_shift_range= [-30, 30], # horizontal shift\n",
        "  height_shift_range= [-5, 5] , # vertical shift\n",
        "  zoom_range= 0.2,\n",
        "  vertical_flip= True , # vertical flip\n",
        "  brightness_range= [0.2, 1.5]\n",
        "    )\n",
        "\n",
        "\n",
        "  images_train = pickle.load(open(\"train_merged.pkl\", 'rb'))\n",
        "  labels_train = pickle.load(open(\"train_merged_label.pkl\", 'rb'))\n",
        "\n",
        "  train_index, val_index = next (skf.split (images_train, list(labels_train.values())))\n",
        "\n",
        "  x_train = {i: images_train[list(images_train.keys())[i]] for i in train_index}\n",
        "  x_valid = {i: images_train[list(images_train.keys())[i]] for i in val_index}\n",
        "\n",
        "  y_trainn = {i: labels_train[list(labels_train.keys())[i]] for i in train_index}\n",
        "  y_validd = {i: labels_train[list(labels_train.keys())[i]] for i in val_index}\n",
        "\n",
        "\n",
        "  ################## preparing\n",
        "\n",
        "  x_train_slo, x_train_oct, y_train = preparing(x_train,y_trainn)\n",
        "  x_valid_slo, x_valid_oct, y_valid = preparing(x_valid,y_validd)\n",
        "\n",
        "  ################# Augmentation\n",
        "\n",
        "  ############ slo\n",
        "  x_train_aug =np.zeros_like(x_train_slo, dtype=np.float32)\n",
        "\n",
        "  y_train_aug =np.zeros_like(y_train, dtype=np.float32)\n",
        "\n",
        "\n",
        "  for i in range(len(x_train_slo)):\n",
        "\n",
        "    x1= x_train_slo[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen_slo.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_aug [i] = y_train[i]\n",
        "\n",
        "  x_train_slo = np.concatenate ((x_train_slo, x_train_aug), axis=0)\n",
        "\n",
        "  y_train_slo = np.concatenate ((y_train, y_train_aug), axis = 0)\n",
        "\n",
        "  ############ OCT\n",
        "  x_train_aug =np.zeros_like(x_train_oct, dtype=np.float32)\n",
        "\n",
        "  y_train_aug =np.zeros_like(y_train, dtype=np.float32)\n",
        "\n",
        "  for i in range(len(x_train_oct)):\n",
        "\n",
        "    x1= x_train_oct[i,:,:,:].copy()\n",
        "\n",
        "    x1=x1.reshape((1, ) + x1.shape)\n",
        "\n",
        "    x = datagen_oct.flow(x1, batch_size=1, seed=42) # to make the result reproducible\n",
        "\n",
        "    x_train_aug [i,:,:,:] = x.next()\n",
        "\n",
        "    y_train_aug [i] = y_train[i]\n",
        "\n",
        "  x_train_oct = np.concatenate ((x_train_oct, x_train_aug), axis=0)\n",
        "\n",
        "  y_train_oct = np.concatenate ((y_train, y_train_aug), axis = 0)\n",
        "\n",
        "\n",
        "  indices = np.random.permutation (len (x_train_slo))\n",
        "  x_train_slo = x_train_slo [indices]\n",
        "  y_train_slo = y_train_slo [indices]\n",
        "\n",
        "  x_train_oct = x_train_oct [indices]\n",
        "  y_train_oct = y_train_oct [indices]\n",
        "\n",
        "\n",
        "  x_train_slo = np.repeat (x_train_slo, repeats = 3, axis = 3)\n",
        "\n",
        "  x_train_oct = np.repeat (x_train_oct, repeats = 3, axis = 3)\n",
        "\n",
        "  x_valid_slo = np.repeat (x_valid_slo, repeats = 3, axis = 3)\n",
        "\n",
        "  x_valid_oct = np.repeat (x_valid_oct, repeats = 3, axis = 3)\n",
        "\n",
        "\n",
        "  ####################################################################\n",
        "  # classification via my model\n",
        "  ####################################################################\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128])\n",
        "\n",
        "  model = classifier (trial)\n",
        "\n",
        "\n",
        "  # Generate our trial model.\n",
        "\n",
        "\n",
        "  model.fit([x_train_slo, x_train_oct],\n",
        "            np.asarray(y_train_oct, dtype=np.float64),\n",
        "            batch_size= batch_size,\n",
        "            epochs=50,\n",
        "            callbacks=[TFKerasPruningCallback(trial, \"val_accuracy\"), #EarlyStopping(patience=10, verbose=1),\n",
        "            ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6),\n",
        "            ModelCheckpoint(f'slo_oct.h5', verbose=1, save_best_only=True, save_weights_only=True)],\n",
        "            validation_data=([x_valid_slo, x_valid_oct] , np.asarray(y_valid, dtype=np.float64)),\n",
        "            )\n",
        "  model.load_weights(f'slo_oct.h5')\n",
        "  score = model.evaluate ([x_valid_slo, x_valid_oct], np.asarray(y_valid, dtype=np.float64), verbose = 1)\n",
        "\n",
        "  return score [1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s09LdTP57YR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3fad77-2e78-470d-f9f6-097a84ebaef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-28 08:38:32,458] A new study created in memory with name: no-name-323bdc79-3b6d-4885-b225-be0c50142965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.7669 - accuracy: 0.5296\n",
            "Epoch 1: val_loss improved from inf to 0.58922, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 19s 1s/step - loss: 4.7669 - accuracy: 0.5296 - val_loss: 0.5892 - val_accuracy: 0.6047 - lr: 4.2395e-04\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 4.3263 - accuracy: 0.4970\n",
            "Epoch 2: val_loss improved from 0.58922 to 0.35785, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 4s 401ms/step - loss: 4.3263 - accuracy: 0.4970 - val_loss: 0.3578 - val_accuracy: 0.9535 - lr: 4.2395e-04\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.6656 - accuracy: 0.5858\n",
            "Epoch 3: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 2.6656 - accuracy: 0.5858 - val_loss: 0.4051 - val_accuracy: 0.9070 - lr: 4.2395e-04\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.4458 - accuracy: 0.5888\n",
            "Epoch 4: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.4458 - accuracy: 0.5888 - val_loss: 0.3977 - val_accuracy: 0.8605 - lr: 4.2395e-04\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 2.0616 - accuracy: 0.6065\n",
            "Epoch 5: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 2.0616 - accuracy: 0.6065 - val_loss: 0.3911 - val_accuracy: 0.9070 - lr: 4.2395e-04\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.9642 - accuracy: 0.6272\n",
            "Epoch 6: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 1.9642 - accuracy: 0.6272 - val_loss: 0.4167 - val_accuracy: 0.8372 - lr: 4.2395e-04\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.6664 - accuracy: 0.6213\n",
            "Epoch 7: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 1.6664 - accuracy: 0.6213 - val_loss: 0.4237 - val_accuracy: 0.7907 - lr: 4.2395e-04\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.8768 - accuracy: 0.6036\n",
            "Epoch 8: val_loss did not improve from 0.35785\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 1.8768 - accuracy: 0.6036 - val_loss: 0.3630 - val_accuracy: 0.9070 - lr: 4.2395e-04\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3685 - accuracy: 0.6716\n",
            "Epoch 9: val_loss improved from 0.35785 to 0.30859, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 1.3685 - accuracy: 0.6716 - val_loss: 0.3086 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.6272\n",
            "Epoch 10: val_loss improved from 0.30859 to 0.29818, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 1.3020 - accuracy: 0.6272 - val_loss: 0.2982 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1873 - accuracy: 0.6893\n",
            "Epoch 11: val_loss did not improve from 0.29818\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 1.1873 - accuracy: 0.6893 - val_loss: 0.3041 - val_accuracy: 0.9535 - lr: 4.2395e-04\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.1357 - accuracy: 0.6746\n",
            "Epoch 12: val_loss did not improve from 0.29818\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 1.1357 - accuracy: 0.6746 - val_loss: 0.3473 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 1.0189 - accuracy: 0.7249\n",
            "Epoch 13: val_loss did not improve from 0.29818\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 1.0189 - accuracy: 0.7249 - val_loss: 0.3292 - val_accuracy: 0.9535 - lr: 4.2395e-04\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7312 - accuracy: 0.7515\n",
            "Epoch 14: val_loss improved from 0.29818 to 0.28639, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 190ms/step - loss: 0.7312 - accuracy: 0.7515 - val_loss: 0.2864 - val_accuracy: 0.9535 - lr: 4.2395e-04\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8497 - accuracy: 0.7485\n",
            "Epoch 15: val_loss improved from 0.28639 to 0.27072, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 172ms/step - loss: 0.8497 - accuracy: 0.7485 - val_loss: 0.2707 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8951 - accuracy: 0.7189\n",
            "Epoch 16: val_loss did not improve from 0.27072\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.8951 - accuracy: 0.7189 - val_loss: 0.2755 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.7219\n",
            "Epoch 17: val_loss did not improve from 0.27072\n",
            "11/11 [==============================] - 1s 106ms/step - loss: 0.8847 - accuracy: 0.7219 - val_loss: 0.2919 - val_accuracy: 0.8837 - lr: 4.2395e-04\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8500 - accuracy: 0.7219\n",
            "Epoch 18: val_loss improved from 0.27072 to 0.26999, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.8500 - accuracy: 0.7219 - val_loss: 0.2700 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.9203 - accuracy: 0.7426\n",
            "Epoch 19: val_loss improved from 0.26999 to 0.25082, saving model to slo_oct.h5\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 0.9203 - accuracy: 0.7426 - val_loss: 0.2508 - val_accuracy: 0.9070 - lr: 4.2395e-04\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8004 - accuracy: 0.7574\n",
            "Epoch 20: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.8004 - accuracy: 0.7574 - val_loss: 0.2604 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8520 - accuracy: 0.7160\n",
            "Epoch 21: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.8520 - accuracy: 0.7160 - val_loss: 0.2732 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.7485\n",
            "Epoch 22: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.7393 - accuracy: 0.7485 - val_loss: 0.2951 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6541 - accuracy: 0.7633\n",
            "Epoch 23: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.6541 - accuracy: 0.7633 - val_loss: 0.2775 - val_accuracy: 0.9535 - lr: 4.2395e-04\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.6304 - accuracy: 0.7959\n",
            "Epoch 24: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.6304 - accuracy: 0.7959 - val_loss: 0.2921 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8314\n",
            "Epoch 25: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4620 - accuracy: 0.8314 - val_loss: 0.3082 - val_accuracy: 0.9070 - lr: 4.2395e-04\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.8047\n",
            "Epoch 26: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5057 - accuracy: 0.8047 - val_loss: 0.2708 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5824 - accuracy: 0.8136\n",
            "Epoch 27: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5824 - accuracy: 0.8136 - val_loss: 0.2561 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.7751\n",
            "Epoch 28: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.5907 - accuracy: 0.7751 - val_loss: 0.2569 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.8166\n",
            "Epoch 29: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.5035 - accuracy: 0.8166 - val_loss: 0.2629 - val_accuracy: 0.9302 - lr: 4.2395e-04\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5244 - accuracy: 0.8343\n",
            "Epoch 30: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5244 - accuracy: 0.8343 - val_loss: 0.2620 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8402\n",
            "Epoch 31: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.3807 - accuracy: 0.8402 - val_loss: 0.2629 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5575 - accuracy: 0.8018\n",
            "Epoch 32: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.5575 - accuracy: 0.8018 - val_loss: 0.2633 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8521\n",
            "Epoch 33: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.3677 - accuracy: 0.8521 - val_loss: 0.2637 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8314\n",
            "Epoch 34: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.4720 - accuracy: 0.8314 - val_loss: 0.2655 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8373\n",
            "Epoch 35: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 111ms/step - loss: 0.4812 - accuracy: 0.8373 - val_loss: 0.2665 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8580\n",
            "Epoch 36: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 109ms/step - loss: 0.4061 - accuracy: 0.8580 - val_loss: 0.2665 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8462\n",
            "Epoch 37: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.3367 - accuracy: 0.8462 - val_loss: 0.2688 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.8195\n",
            "Epoch 38: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5112 - accuracy: 0.8195 - val_loss: 0.2704 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.8254\n",
            "Epoch 39: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4446 - accuracy: 0.8254 - val_loss: 0.2706 - val_accuracy: 0.9302 - lr: 4.2395e-05\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.7929\n",
            "Epoch 40: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.5027 - accuracy: 0.7929 - val_loss: 0.2708 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4824 - accuracy: 0.8225\n",
            "Epoch 41: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.4824 - accuracy: 0.8225 - val_loss: 0.2709 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.8225\n",
            "Epoch 42: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4426 - accuracy: 0.8225 - val_loss: 0.2708 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.8373\n",
            "Epoch 43: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4225 - accuracy: 0.8373 - val_loss: 0.2711 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.8225\n",
            "Epoch 44: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4690 - accuracy: 0.8225 - val_loss: 0.2713 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.8225\n",
            "Epoch 45: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 110ms/step - loss: 0.4320 - accuracy: 0.8225 - val_loss: 0.2714 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.8107\n",
            "Epoch 46: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.5351 - accuracy: 0.8107 - val_loss: 0.2716 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8284\n",
            "Epoch 47: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 0.4531 - accuracy: 0.8284 - val_loss: 0.2715 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.8284\n",
            "Epoch 48: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4839 - accuracy: 0.8284 - val_loss: 0.2715 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4535 - accuracy: 0.8195\n",
            "Epoch 49: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 107ms/step - loss: 0.4535 - accuracy: 0.8195 - val_loss: 0.2716 - val_accuracy: 0.9302 - lr: 4.2395e-06\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.8254\n",
            "Epoch 50: val_loss did not improve from 0.25082\n",
            "11/11 [==============================] - 1s 108ms/step - loss: 0.4656 - accuracy: 0.8254 - val_loss: 0.2716 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.2508 - accuracy: 0.9070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-28 08:41:03,247] Trial 0 finished with value: 0.9069767594337463 and parameters: {'batch_size': 32, 'dropout_l0': 0.7, 'n_layers': 3, 'n_units_l0': 417, 'n_units_l1': 87, 'dropout_l1': 0.30000000000000004, 'n_units_l2': 48, 'dropout_l2': 0.4, 'lr': 0.0004239450247224403}. Best is trial 0 with value: 0.9069767594337463.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.7085 - accuracy: 0.4941\n",
            "Epoch 1: val_loss improved from inf to 0.68395, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 26s 2s/step - loss: 0.7085 - accuracy: 0.4941 - val_loss: 0.6840 - val_accuracy: 0.4651 - lr: 1.8553e-05\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6965 - accuracy: 0.5118\n",
            "Epoch 2: val_loss improved from 0.68395 to 0.67442, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 377ms/step - loss: 0.6965 - accuracy: 0.5118 - val_loss: 0.6744 - val_accuracy: 0.5349 - lr: 1.8553e-05\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6692 - accuracy: 0.5799\n",
            "Epoch 3: val_loss improved from 0.67442 to 0.64749, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 373ms/step - loss: 0.6692 - accuracy: 0.5799 - val_loss: 0.6475 - val_accuracy: 0.7442 - lr: 1.8553e-05\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6434 - accuracy: 0.6657\n",
            "Epoch 4: val_loss improved from 0.64749 to 0.61021, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 4s 796ms/step - loss: 0.6434 - accuracy: 0.6657 - val_loss: 0.6102 - val_accuracy: 0.8605 - lr: 1.8553e-05\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7219\n",
            "Epoch 5: val_loss improved from 0.61021 to 0.55525, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 301ms/step - loss: 0.6088 - accuracy: 0.7219 - val_loss: 0.5552 - val_accuracy: 0.8140 - lr: 1.8553e-05\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7426\n",
            "Epoch 6: val_loss improved from 0.55525 to 0.48391, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 3s 621ms/step - loss: 0.5602 - accuracy: 0.7426 - val_loss: 0.4839 - val_accuracy: 0.8140 - lr: 1.8553e-05\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.7515\n",
            "Epoch 7: val_loss improved from 0.48391 to 0.40593, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 317ms/step - loss: 0.5301 - accuracy: 0.7515 - val_loss: 0.4059 - val_accuracy: 0.9535 - lr: 1.8553e-05\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8077\n",
            "Epoch 8: val_loss improved from 0.40593 to 0.33364, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 3s 604ms/step - loss: 0.4500 - accuracy: 0.8077 - val_loss: 0.3336 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8314\n",
            "Epoch 9: val_loss improved from 0.33364 to 0.27827, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 307ms/step - loss: 0.4079 - accuracy: 0.8314 - val_loss: 0.2783 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8343\n",
            "Epoch 10: val_loss improved from 0.27827 to 0.25422, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 318ms/step - loss: 0.3786 - accuracy: 0.8343 - val_loss: 0.2542 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.3415 - accuracy: 0.8462\n",
            "Epoch 11: val_loss improved from 0.25422 to 0.22264, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 327ms/step - loss: 0.3415 - accuracy: 0.8462 - val_loss: 0.2226 - val_accuracy: 0.9535 - lr: 1.8553e-05\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.8905\n",
            "Epoch 12: val_loss improved from 0.22264 to 0.21084, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 316ms/step - loss: 0.2794 - accuracy: 0.8905 - val_loss: 0.2108 - val_accuracy: 0.9535 - lr: 1.8553e-05\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.9024\n",
            "Epoch 13: val_loss improved from 0.21084 to 0.20613, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 3s 558ms/step - loss: 0.2658 - accuracy: 0.9024 - val_loss: 0.2061 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.9201\n",
            "Epoch 14: val_loss did not improve from 0.20613\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 0.2514 - accuracy: 0.9201 - val_loss: 0.2065 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.9053\n",
            "Epoch 15: val_loss improved from 0.20613 to 0.20442, saving model to slo_oct.h5\n",
            "6/6 [==============================] - 2s 309ms/step - loss: 0.2563 - accuracy: 0.9053 - val_loss: 0.2044 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9083\n",
            "Epoch 16: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 0.2299 - accuracy: 0.9083 - val_loss: 0.2049 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.8964\n",
            "Epoch 17: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 0.2314 - accuracy: 0.8964 - val_loss: 0.2084 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9379\n",
            "Epoch 18: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 0.1742 - accuracy: 0.9379 - val_loss: 0.2175 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.9260\n",
            "Epoch 19: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 0.1945 - accuracy: 0.9260 - val_loss: 0.2267 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9290\n",
            "Epoch 20: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 181ms/step - loss: 0.1702 - accuracy: 0.9290 - val_loss: 0.2254 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9231\n",
            "Epoch 21: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 0.1701 - accuracy: 0.9231 - val_loss: 0.2240 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9645\n",
            "Epoch 22: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 0.1132 - accuracy: 0.9645 - val_loss: 0.2287 - val_accuracy: 0.9302 - lr: 1.8553e-05\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.9290\n",
            "Epoch 23: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 0.1728 - accuracy: 0.9290 - val_loss: 0.2390 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.9379\n",
            "Epoch 24: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.1519 - accuracy: 0.9379 - val_loss: 0.2475 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9438\n",
            "Epoch 25: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 196ms/step - loss: 0.1630 - accuracy: 0.9438 - val_loss: 0.2410 - val_accuracy: 0.9070 - lr: 1.8553e-05\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9379\n",
            "Epoch 26: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.1592 - accuracy: 0.9379 - val_loss: 0.2402 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.9408\n",
            "Epoch 27: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 187ms/step - loss: 0.1574 - accuracy: 0.9408 - val_loss: 0.2398 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9586\n",
            "Epoch 28: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 0.1143 - accuracy: 0.9586 - val_loss: 0.2399 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9556\n",
            "Epoch 29: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 0.1188 - accuracy: 0.9556 - val_loss: 0.2402 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9527\n",
            "Epoch 30: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 186ms/step - loss: 0.1207 - accuracy: 0.9527 - val_loss: 0.2402 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9615\n",
            "Epoch 31: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 0.1289 - accuracy: 0.9615 - val_loss: 0.2406 - val_accuracy: 0.9070 - lr: 1.8553e-06\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9615\n",
            "Epoch 32: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 0.1089 - accuracy: 0.9615 - val_loss: 0.2406 - val_accuracy: 0.9302 - lr: 1.8553e-06\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.9615\n",
            "Epoch 33: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 183ms/step - loss: 0.1118 - accuracy: 0.9615 - val_loss: 0.2411 - val_accuracy: 0.9302 - lr: 1.8553e-06\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9527\n",
            "Epoch 34: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 185ms/step - loss: 0.1140 - accuracy: 0.9527 - val_loss: 0.2414 - val_accuracy: 0.9302 - lr: 1.8553e-06\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.9556\n",
            "Epoch 35: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 0.1220 - accuracy: 0.9556 - val_loss: 0.2419 - val_accuracy: 0.9302 - lr: 1.8553e-06\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9467\n",
            "Epoch 36: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 188ms/step - loss: 0.1441 - accuracy: 0.9467 - val_loss: 0.2424 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9615\n",
            "Epoch 37: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 0.1084 - accuracy: 0.9615 - val_loss: 0.2428 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9497\n",
            "Epoch 38: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 189ms/step - loss: 0.1298 - accuracy: 0.9497 - val_loss: 0.2427 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9527\n",
            "Epoch 39: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 182ms/step - loss: 0.1207 - accuracy: 0.9527 - val_loss: 0.2427 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9497\n",
            "Epoch 40: val_loss did not improve from 0.20442\n",
            "6/6 [==============================] - 1s 184ms/step - loss: 0.1135 - accuracy: 0.9497 - val_loss: 0.2425 - val_accuracy: 0.9302 - lr: 1.0000e-06\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9645"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
        "\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxyq_j5Q2-f3",
        "outputId": "7e81326a-a134-4385-80bf-b45501957115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  73\n",
            "  Number of pruned trials:  21\n",
            "  Number of complete trials:  51\n",
            "Best trial:\n",
            "  Value:  0.7096773982048035\n",
            "  Params: \n",
            "    batch_size: 64\n",
            "    n_layers: 3\n",
            "    n_units_l0: 591\n",
            "    dropout_l0: 0.30000000000000004\n",
            "    n_units_l1: 19\n",
            "    dropout_l1: 0.0\n",
            "    n_units_l2: 182\n",
            "    dropout_l2: 0.0\n",
            "    lr: 0.00011541182649610528\n"
          ]
        }
      ],
      "source": [
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "  print(\"    {}: {}\".format(key, value))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}